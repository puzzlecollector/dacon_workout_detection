{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRANSFORMER 5.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMXLdHEN8K0-",
        "outputId": "b6f003a9-d3cf-49d8-99f8-ccdda56a030e"
      },
      "source": [
        "pip install tsaug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tsaug\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/6e/8b1be145a32bba360c14322c3b87ad93d6227c46528d482c84eefe54094b/tsaug-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from tsaug) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from tsaug) (1.19.5)\n",
            "Installing collected packages: tsaug\n",
            "Successfully installed tsaug-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rprtMKe8Sck"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os, datetime \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *  \n",
        "from tensorflow.keras.callbacks import *\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold \n",
        "from tqdm import tqdm\n",
        "import random \n",
        "import time\n",
        "import pywt\n",
        "import tsaug\n",
        "from tsaug import TimeWarp, Crop, Quantize, Drift, Reverse "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJY7CLVl8WJJ"
      },
      "source": [
        "## Load data \n",
        "train_features = pd.read_csv('drive/MyDrive/movement_detection/train_features.csv')\n",
        "train_labels = pd.read_csv('drive/MyDrive/movement_detection/train_labels.csv')\n",
        "test_features = pd.read_csv('drive/MyDrive/movement_detection/test_features.csv')\n",
        "sample_submission = pd.read_csv('drive/MyDrive/movement_detection/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYiVgwaX8XZS",
        "outputId": "3729bc97-f8eb-4d29-e7bc-32b8d51b1667"
      },
      "source": [
        "X = tf.reshape(np.array(train_features.iloc[:,2:]),[-1, 600, 6])\n",
        "X = np.asarray(X) \n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3125, 600, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwQ0Lh-B9Bau",
        "outputId": "102c7d61-565f-4d28-865f-2bdaf7683652"
      },
      "source": [
        "y = train_labels['label'].values\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3125,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qX5NoJz9C27"
      },
      "source": [
        "batch_size = 32\n",
        "seq_len = 600 # temporary \n",
        "d_k = 256 \n",
        "d_v = 256\n",
        "n_heads = 12 \n",
        "ff_dim = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT13u_4n9EHG"
      },
      "source": [
        "class SingleAttention(Layer):\n",
        "    def __init__(self, d_k, d_v):\n",
        "        super(SingleAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.query = Dense(self.d_k, \n",
        "                       input_shape=input_shape, \n",
        "                       kernel_initializer='glorot_uniform', \n",
        "                       bias_initializer='glorot_uniform')\n",
        "    \n",
        "        self.key = Dense(self.d_k, \n",
        "                     input_shape=input_shape, \n",
        "                     kernel_initializer='glorot_uniform', \n",
        "                     bias_initializer='glorot_uniform')\n",
        "    \n",
        "        self.value = Dense(self.d_v, \n",
        "                       input_shape=input_shape, \n",
        "                       kernel_initializer='glorot_uniform', \n",
        "                       bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "        q = self.query(inputs[0])\n",
        "        k = self.key(inputs[1])\n",
        "\n",
        "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
        "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
        "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
        "    \n",
        "        v = self.value(inputs[2])\n",
        "        attn_out = tf.matmul(attn_weights, v)\n",
        "        return attn_out    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQw51KcO9FpG"
      },
      "source": [
        "class MultiAttention(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads):\n",
        "        super(MultiAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.attn_heads = list()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        for n in range(self.n_heads):\n",
        "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
        "    \n",
        "        self.linear = Dense(input_shape[0][-1], \n",
        "                        input_shape=input_shape, \n",
        "                        kernel_initializer='glorot_uniform', \n",
        "                        bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
        "        concat_attn = tf.concat(attn, axis=-1)\n",
        "        multi_linear = self.linear(concat_attn)\n",
        "        return multi_linear   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEcp2iKo9G97"
      },
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.attn_heads = []\n",
        "        self.dropout_rate = dropout \n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
        "        self.attn_dropout = Dropout(self.dropout_rate)\n",
        "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
        "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
        "        self.ff_dropout = Dropout(self.dropout_rate)\n",
        "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
        "  \n",
        "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq) \n",
        "        attn_layer = self.attn_multi(inputs) \n",
        "        attn_layer = self.attn_dropout(attn_layer)\n",
        "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
        "        ff_layer = self.ff_conv1D_1(attn_layer)  \n",
        "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
        "        ff_layer = self.ff_dropout(ff_layer)\n",
        "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
        "        return ff_layer \n",
        "\n",
        "    def get_config(self): # Needed for saving and loading model with custom layer\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'d_k': self.d_k,\n",
        "                   'd_v': self.d_v,\n",
        "                   'n_heads': self.n_heads,\n",
        "                   'ff_dim': self.ff_dim,\n",
        "                   'attn_heads': self.attn_heads,\n",
        "                   'dropout_rate': self.dropout_rate})\n",
        "        return config\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfRhKjgB9Pr-"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMttqCv19Qyy"
      },
      "source": [
        "def build_model(seq_len, features): \n",
        "  inputs = Input(shape=(seq_len,features))   \n",
        "  bn = BatchNormalization()(inputs)    \n",
        "\n",
        "  conv = Conv1D(256, 5, activation = 'relu', padding = 'same')(bn) \n",
        "  bn = BatchNormalization()(conv) \n",
        "  maxpool = MaxPooling1D()(bn) \n",
        "  conv = Conv1D(256, 5, activation = 'relu', padding = 'same')(maxpool) \n",
        "  bn = BatchNormalization()(conv) \n",
        "  features = MaxPooling1D()(bn) \n",
        "\n",
        "  pos_encoding = positional_encoding(seq_len, d_k)    \n",
        "  features *= tf.math.sqrt(tf.cast(d_k, tf.float32)) # scale  \n",
        "  features += pos_encoding[:, :features.shape[1], :] # add positional encoding \n",
        "\n",
        "  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "\n",
        "  x = attn_layer1((features, features, features))   \n",
        "  x = attn_layer2((x, x, x)) \n",
        "  x = attn_layer3((x, x, x)) \n",
        "\n",
        "  bi_gru = Bidirectional(GRU(128, return_sequences = False))(x) \n",
        "  dropout = Dropout(0.25)(bi_gru) \n",
        "  dense = Dense(128, activation = 'relu')(dropout) \n",
        "  bn = BatchNormalization()(dense) \n",
        "  outputs = Dense(61, activation='softmax')(bn) \n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psK1tSNr9TdL",
        "outputId": "93f365dd-e495-493b-8c3f-45a0a496c339"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits = 10, random_state = 960418, shuffle = True)\n",
        "for idx,(train_idx, val_idx) in enumerate(kfold.split(X,y)):   \n",
        "    print(\"... Validating on fold {} ...\".format(idx+1))  \n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx] \n",
        "    \n",
        "    ##### augment data #####\n",
        "    print(\"... Augmenting Data ...\")\n",
        "    X_augmented = [] \n",
        "    y_augmented = [] \n",
        "\n",
        "    for i in tqdm(range(X_train.shape[0]), position = 0, leave = True): \n",
        "        for j in range(10): # add random shift \n",
        "            shifted = np.roll(X_train[i], int(random.random() * 600)) \n",
        "            X_augmented.append(shifted) \n",
        "            y_augmented.append(y_train[i]) \n",
        "        for j in range(10): # add noise \n",
        "            noised = np.random.normal(0, 1, X_train[i].shape) + X_train[i] \n",
        "            X_augmented.append(noised) \n",
        "            y_augmented.append(y_train[i])   \n",
        "    \n",
        "\n",
        "    X_cropped = Crop(random.randint(300, 580), resize = 600).augment(X_train) \n",
        "    X_warped = TimeWarp(random.randint(3,20)).augment(X_train)  \n",
        "    #X_reversed = Reverse().augment(X_train) \n",
        "    X_quantized = Quantize(random.randint(10,100)).augment(X_train) \n",
        "    x_drift = Drift(max_drift=(0.1,0.5)).augment(X_train)\n",
        "    x_drift2 = Drift(max_drift=(0.1,0.5)).augment(X_train)\n",
        "\n",
        "    X_augmented = np.asarray(X_augmented) \n",
        "    y_augmented = np.asarray(y_augmented)    \n",
        "\n",
        "    X_train = np.concatenate([X_train, X_augmented, X_cropped, X_warped, x_drift, x_drift2, X_quantized]) \n",
        "    y_train = np.concatenate([y_train, y_augmented, y_train, y_train, y_train, y_train, y_train])  \n",
        "\n",
        "    print(\"Train shapes\")\n",
        "    print(X_train.shape, y_train.shape)  \n",
        "\n",
        "    ###### feature engineering data ##### \n",
        "    print(\"... DFFT Feature Engineering ...\")\n",
        "    X_fourier_real = [] \n",
        "    X_fourier_imag = [] \n",
        "    for i in tqdm(range(X_train.shape[0]), position = 0, leave = True):  \n",
        "        real_part = np.fft.fft(X_train[i]).real \n",
        "        imag_part = np.fft.fft(X_train[i]).imag \n",
        "        X_fourier_real.append(real_part)\n",
        "        X_fourier_imag.append(imag_part) \n",
        "    \n",
        "    X_fourier_real = np.asarray(X_fourier_real)  \n",
        "    X_fourier_imag = np.asarray(X_fourier_imag)\n",
        "    \n",
        "    \n",
        "    X_val_fourier_real = [] \n",
        "    X_val_fourier_imag = [] \n",
        "    for i in tqdm(range(X_val.shape[0]), position = 0, leave = True):\n",
        "        real_part = np.fft.fft(X_val[i]).real \n",
        "        imag_part = np.fft.fft(X_val[i]).imag \n",
        "        X_val_fourier_real.append(real_part) \n",
        "        X_val_fourier_imag.append(imag_part)\n",
        "    \n",
        "    X_val_fourier_real = np.asarray(X_val_fourier_real) \n",
        "    X_val_fourier_imag = np.asarray(X_val_fourier_imag)\n",
        "    \n",
        "    X_train = np.concatenate([X_train, X_fourier_real, X_fourier_imag], axis = 2)  \n",
        "    X_val = np.concatenate([X_val, X_val_fourier_real, X_val_fourier_imag], axis = 2)\n",
        "\n",
        "    ##### train model #####  \n",
        "    print(\"... Building Model ...\")\n",
        "    # we have 18 features after feature engineering \n",
        "    model = build_model(600, 18) \n",
        "    print(\"... Training ...\") \n",
        "    model_path = 'drive/MyDrive/movement_detection/kfold' + str(idx+1) + '/TRANSFORMER5_epoch_{epoch:03d}_val_{val_loss:.3f}_accuracy_{val_accuracy:.3f}.h5'\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 1, verbose = 1, factor = 0.8)\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5) \n",
        "\n",
        "    model.fit(X_train,\n",
        "              y_train,\n",
        "              epochs = 200,\n",
        "              batch_size = 32, # hyperparameter  \n",
        "              validation_data = (X_val, y_val), \n",
        "              callbacks = [learning_rate_reduction, checkpoint, early_stopping])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 45/2812 [00:00<00:06, 443.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Validating on fold 1 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:06<00:00, 448.98it/s]\n",
            "  1%|▏         | 948/73112 [00:00<00:07, 9471.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73112, 600, 6) (73112,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73112/73112 [00:10<00:00, 7245.22it/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 9472.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2285/2285 [==============================] - 710s 299ms/step - loss: 2.3071 - accuracy: 0.5016 - val_loss: 1.5095 - val_accuracy: 0.6038\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.50947, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER5_epoch_001_val_1.509_accuracy_0.604.h5\n",
            "Epoch 2/200\n",
            "2285/2285 [==============================] - 676s 296ms/step - loss: 1.3956 - accuracy: 0.6180 - val_loss: 1.0399 - val_accuracy: 0.7029\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.50947 to 1.03985, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER5_epoch_002_val_1.040_accuracy_0.703.h5\n",
            "Epoch 3/200\n",
            "2285/2285 [==============================] - 674s 295ms/step - loss: 1.0320 - accuracy: 0.7086 - val_loss: 0.9562 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.03985 to 0.95620, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER5_epoch_003_val_0.956_accuracy_0.741.h5\n",
            "Epoch 4/200\n",
            "2285/2285 [==============================] - 674s 295ms/step - loss: 0.8095 - accuracy: 0.7651 - val_loss: 0.9118 - val_accuracy: 0.7348\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.95620 to 0.91176, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER5_epoch_004_val_0.912_accuracy_0.735.h5\n",
            "Epoch 5/200\n",
            "2285/2285 [==============================] - 672s 294ms/step - loss: 0.7034 - accuracy: 0.7955 - val_loss: 0.9367 - val_accuracy: 0.7476\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.91176\n",
            "Epoch 6/200\n",
            "2285/2285 [==============================] - 675s 295ms/step - loss: 0.5467 - accuracy: 0.8401 - val_loss: 0.8452 - val_accuracy: 0.7796\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.91176 to 0.84521, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER5_epoch_006_val_0.845_accuracy_0.780.h5\n",
            "Epoch 7/200\n",
            "2285/2285 [==============================] - 675s 296ms/step - loss: 0.4598 - accuracy: 0.8635 - val_loss: 0.9938 - val_accuracy: 0.7476\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.84521\n",
            "Epoch 8/200\n",
            "2285/2285 [==============================] - 675s 295ms/step - loss: 0.3822 - accuracy: 0.8845 - val_loss: 0.9231 - val_accuracy: 0.7796\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.84521\n",
            "Epoch 9/200\n",
            "2285/2285 [==============================] - 675s 295ms/step - loss: 0.3181 - accuracy: 0.9043 - val_loss: 0.9825 - val_accuracy: 0.7604\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.84521\n",
            "Epoch 10/200\n",
            "2285/2285 [==============================] - 676s 296ms/step - loss: 0.2706 - accuracy: 0.9152 - val_loss: 0.9439 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.84521\n",
            "Epoch 11/200\n",
            "2285/2285 [==============================] - 676s 296ms/step - loss: 0.2313 - accuracy: 0.9284 - val_loss: 0.9736 - val_accuracy: 0.7732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 48/2812 [00:00<00:05, 473.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.84521\n",
            "... Validating on fold 2 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:06<00:00, 451.49it/s]\n",
            "  1%|          | 895/73112 [00:00<00:08, 8941.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73112, 600, 6) (73112,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73112/73112 [00:10<00:00, 7287.57it/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 9031.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2285/2285 [==============================] - 710s 300ms/step - loss: 2.2872 - accuracy: 0.5035 - val_loss: 1.6971 - val_accuracy: 0.6070\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.69706, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER5_epoch_001_val_1.697_accuracy_0.607.h5\n",
            "Epoch 2/200\n",
            "2285/2285 [==============================] - 680s 298ms/step - loss: 1.3158 - accuracy: 0.6397 - val_loss: 1.1054 - val_accuracy: 0.7029\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.69706 to 1.10536, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER5_epoch_002_val_1.105_accuracy_0.703.h5\n",
            "Epoch 3/200\n",
            "2285/2285 [==============================] - 679s 297ms/step - loss: 1.0191 - accuracy: 0.7070 - val_loss: 1.1034 - val_accuracy: 0.6965\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.10536 to 1.10335, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER5_epoch_003_val_1.103_accuracy_0.696.h5\n",
            "Epoch 4/200\n",
            "2285/2285 [==============================] - 674s 295ms/step - loss: 0.8423 - accuracy: 0.7549 - val_loss: 1.0399 - val_accuracy: 0.7316\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.10335 to 1.03990, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER5_epoch_004_val_1.040_accuracy_0.732.h5\n",
            "Epoch 5/200\n",
            "2285/2285 [==============================] - 668s 292ms/step - loss: 0.6805 - accuracy: 0.7994 - val_loss: 1.0708 - val_accuracy: 0.7636\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.03990\n",
            "Epoch 6/200\n",
            "2285/2285 [==============================] - 667s 292ms/step - loss: 0.5293 - accuracy: 0.8438 - val_loss: 1.0220 - val_accuracy: 0.7732\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.03990 to 1.02202, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER5_epoch_006_val_1.022_accuracy_0.773.h5\n",
            "Epoch 7/200\n",
            "2285/2285 [==============================] - 660s 289ms/step - loss: 0.4630 - accuracy: 0.8622 - val_loss: 1.2025 - val_accuracy: 0.7444\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.02202\n",
            "Epoch 8/200\n",
            "2285/2285 [==============================] - 666s 291ms/step - loss: 0.3970 - accuracy: 0.8781 - val_loss: 1.0354 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.02202\n",
            "Epoch 9/200\n",
            "2285/2285 [==============================] - 663s 290ms/step - loss: 0.3268 - accuracy: 0.9016 - val_loss: 1.2114 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.02202\n",
            "Epoch 10/200\n",
            "2285/2285 [==============================] - 671s 294ms/step - loss: 0.2844 - accuracy: 0.9127 - val_loss: 1.2077 - val_accuracy: 0.7604\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.02202\n",
            "Epoch 11/200\n",
            "2285/2285 [==============================] - 675s 295ms/step - loss: 0.2436 - accuracy: 0.9261 - val_loss: 1.2072 - val_accuracy: 0.7732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2812 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.02202\n",
            "... Validating on fold 3 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:06<00:00, 438.48it/s]\n",
            "  1%|          | 870/73112 [00:00<00:08, 8698.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73112, 600, 6) (73112,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73112/73112 [00:09<00:00, 7355.16it/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 8667.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2285/2285 [==============================] - 706s 298ms/step - loss: 2.2965 - accuracy: 0.5018 - val_loss: 1.4984 - val_accuracy: 0.5751\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.49844, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER5_epoch_001_val_1.498_accuracy_0.575.h5\n",
            "Epoch 2/200\n",
            "2285/2285 [==============================] - 681s 298ms/step - loss: 1.5042 - accuracy: 0.6008 - val_loss: 1.1598 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.49844 to 1.15984, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER5_epoch_002_val_1.160_accuracy_0.677.h5\n",
            "Epoch 3/200\n",
            "2285/2285 [==============================] - 682s 298ms/step - loss: 1.1204 - accuracy: 0.6842 - val_loss: 1.0464 - val_accuracy: 0.6805\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.15984 to 1.04643, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER5_epoch_003_val_1.046_accuracy_0.681.h5\n",
            "Epoch 4/200\n",
            "2285/2285 [==============================] - 679s 297ms/step - loss: 0.8785 - accuracy: 0.7466 - val_loss: 0.9785 - val_accuracy: 0.7188\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.04643 to 0.97849, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER5_epoch_004_val_0.978_accuracy_0.719.h5\n",
            "Epoch 5/200\n",
            "2285/2285 [==============================] - 675s 296ms/step - loss: 0.7520 - accuracy: 0.7812 - val_loss: 0.9021 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.97849 to 0.90214, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER5_epoch_005_val_0.902_accuracy_0.741.h5\n",
            "Epoch 6/200\n",
            "2285/2285 [==============================] - 678s 297ms/step - loss: 0.6497 - accuracy: 0.8083 - val_loss: 1.0426 - val_accuracy: 0.7348\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.90214\n",
            "Epoch 7/200\n",
            "2285/2285 [==============================] - 676s 296ms/step - loss: 0.5390 - accuracy: 0.8409 - val_loss: 0.9196 - val_accuracy: 0.7316\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.90214\n",
            "Epoch 8/200\n",
            "2285/2285 [==============================] - 677s 296ms/step - loss: 0.4655 - accuracy: 0.8629 - val_loss: 0.9271 - val_accuracy: 0.7540\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.90214\n",
            "Epoch 9/200\n",
            "2285/2285 [==============================] - 680s 298ms/step - loss: 0.3955 - accuracy: 0.8798 - val_loss: 0.8750 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.90214 to 0.87503, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER5_epoch_009_val_0.875_accuracy_0.751.h5\n",
            "Epoch 10/200\n",
            "2285/2285 [==============================] - 681s 298ms/step - loss: 0.3580 - accuracy: 0.8925 - val_loss: 0.9911 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.87503\n",
            "Epoch 11/200\n",
            "2285/2285 [==============================] - 690s 302ms/step - loss: 0.3249 - accuracy: 0.9021 - val_loss: 0.9341 - val_accuracy: 0.7796\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.87503\n",
            "Epoch 12/200\n",
            "2285/2285 [==============================] - 694s 304ms/step - loss: 0.2820 - accuracy: 0.9140 - val_loss: 0.9775 - val_accuracy: 0.7732\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.87503\n",
            "Epoch 13/200\n",
            "2285/2285 [==============================] - 694s 304ms/step - loss: 0.2541 - accuracy: 0.9225 - val_loss: 0.9785 - val_accuracy: 0.7891\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.87503\n",
            "Epoch 14/200\n",
            "2285/2285 [==============================] - 694s 304ms/step - loss: 0.2278 - accuracy: 0.9305 - val_loss: 0.9568 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.87503\n",
            "... Validating on fold 4 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 43/2812 [00:00<00:06, 424.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:06<00:00, 438.20it/s]\n",
            "  1%|          | 871/73112 [00:00<00:08, 8705.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73112, 600, 6) (73112,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73112/73112 [00:09<00:00, 7405.57it/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 9053.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2285/2285 [==============================] - 708s 299ms/step - loss: 2.2940 - accuracy: 0.5041 - val_loss: 1.3431 - val_accuracy: 0.6198\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.34311, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER5_epoch_001_val_1.343_accuracy_0.620.h5\n",
            "Epoch 2/200\n",
            "2285/2285 [==============================] - 674s 295ms/step - loss: 1.3418 - accuracy: 0.6346 - val_loss: 1.0707 - val_accuracy: 0.6677\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.34311 to 1.07074, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER5_epoch_002_val_1.071_accuracy_0.668.h5\n",
            "Epoch 3/200\n",
            "2285/2285 [==============================] - 674s 295ms/step - loss: 1.0323 - accuracy: 0.7076 - val_loss: 1.0629 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.07074 to 1.06285, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER5_epoch_003_val_1.063_accuracy_0.728.h5\n",
            "Epoch 4/200\n",
            "2285/2285 [==============================] - 677s 296ms/step - loss: 0.8510 - accuracy: 0.7534 - val_loss: 0.8681 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.06285 to 0.86810, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER5_epoch_004_val_0.868_accuracy_0.770.h5\n",
            "Epoch 5/200\n",
            "2285/2285 [==============================] - 681s 298ms/step - loss: 0.6697 - accuracy: 0.8014 - val_loss: 1.0032 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.86810\n",
            "Epoch 6/200\n",
            "2285/2285 [==============================] - 680s 298ms/step - loss: 0.5343 - accuracy: 0.8407 - val_loss: 0.9770 - val_accuracy: 0.7540\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.86810\n",
            "Epoch 7/200\n",
            "2285/2285 [==============================] - 684s 299ms/step - loss: 0.4417 - accuracy: 0.8670 - val_loss: 0.9596 - val_accuracy: 0.7859\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.86810\n",
            "Epoch 8/200\n",
            "2285/2285 [==============================] - 683s 299ms/step - loss: 0.3656 - accuracy: 0.8878 - val_loss: 0.9312 - val_accuracy: 0.7796\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.86810\n",
            "Epoch 9/200\n",
            "2285/2285 [==============================] - 685s 300ms/step - loss: 0.3128 - accuracy: 0.9020 - val_loss: 0.9787 - val_accuracy: 0.7987\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.86810\n",
            "... Validating on fold 5 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 48/2812 [00:00<00:05, 474.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:06<00:00, 440.98it/s]\n",
            "  1%|▏         | 916/73112 [00:00<00:07, 9158.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73112, 600, 6) (73112,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73112/73112 [00:10<00:00, 7121.81it/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 8597.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2285/2285 [==============================] - 716s 302ms/step - loss: 2.2807 - accuracy: 0.5057 - val_loss: 1.3020 - val_accuracy: 0.6677\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.30196, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER5_epoch_001_val_1.302_accuracy_0.668.h5\n",
            "Epoch 2/200\n",
            "2285/2285 [==============================] - 684s 299ms/step - loss: 1.2921 - accuracy: 0.6449 - val_loss: 1.0417 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.30196 to 1.04172, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER5_epoch_002_val_1.042_accuracy_0.716.h5\n",
            "Epoch 3/200\n",
            "2285/2285 [==============================] - 681s 298ms/step - loss: 1.0175 - accuracy: 0.7131 - val_loss: 1.0174 - val_accuracy: 0.7252\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.04172 to 1.01738, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER5_epoch_003_val_1.017_accuracy_0.725.h5\n",
            "Epoch 4/200\n",
            "2285/2285 [==============================] - 685s 300ms/step - loss: 0.8323 - accuracy: 0.7613 - val_loss: 0.9115 - val_accuracy: 0.7668\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.01738 to 0.91147, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER5_epoch_004_val_0.911_accuracy_0.767.h5\n",
            "Epoch 5/200\n",
            "2285/2285 [==============================] - 688s 301ms/step - loss: 0.7316 - accuracy: 0.7880 - val_loss: 0.9061 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.91147 to 0.90607, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER5_epoch_005_val_0.906_accuracy_0.741.h5\n",
            "Epoch 6/200\n",
            "2285/2285 [==============================] - 690s 302ms/step - loss: 0.6374 - accuracy: 0.8145 - val_loss: 0.9259 - val_accuracy: 0.7444\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.90607\n",
            "Epoch 7/200\n",
            "2285/2285 [==============================] - 689s 302ms/step - loss: 0.5124 - accuracy: 0.8500 - val_loss: 0.8850 - val_accuracy: 0.7636\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.90607 to 0.88501, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER5_epoch_007_val_0.885_accuracy_0.764.h5\n",
            "Epoch 8/200\n",
            "2285/2285 [==============================] - 689s 301ms/step - loss: 0.4569 - accuracy: 0.8642 - val_loss: 0.8769 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.88501 to 0.87685, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER5_epoch_008_val_0.877_accuracy_0.751.h5\n",
            "Epoch 9/200\n",
            "2285/2285 [==============================] - 681s 298ms/step - loss: 0.4169 - accuracy: 0.8736 - val_loss: 0.9174 - val_accuracy: 0.7859\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.87685\n",
            "Epoch 10/200\n",
            "2285/2285 [==============================] - 686s 300ms/step - loss: 0.3744 - accuracy: 0.8844 - val_loss: 0.9889 - val_accuracy: 0.7732\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.87685\n",
            "Epoch 11/200\n",
            "2285/2285 [==============================] - 684s 300ms/step - loss: 0.2889 - accuracy: 0.9128 - val_loss: 0.9601 - val_accuracy: 0.7636\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.87685\n",
            "Epoch 12/200\n",
            "2285/2285 [==============================] - 685s 300ms/step - loss: 0.2636 - accuracy: 0.9188 - val_loss: 1.0066 - val_accuracy: 0.7636\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.87685\n",
            "Epoch 13/200\n",
            "2285/2285 [==============================] - 684s 299ms/step - loss: 0.2240 - accuracy: 0.9323 - val_loss: 0.9456 - val_accuracy: 0.7923\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.87685\n",
            "... Validating on fold 6 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 38/2813 [00:00<00:07, 374.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 450.96it/s]\n",
            "  1%|▏         | 943/73138 [00:00<00:07, 9420.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73138, 600, 6) (73138,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73138/73138 [00:10<00:00, 7225.78it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 9149.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2286/2286 [==============================] - 710s 300ms/step - loss: 2.2460 - accuracy: 0.5129 - val_loss: 1.3853 - val_accuracy: 0.6346\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.38533, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER5_epoch_001_val_1.385_accuracy_0.635.h5\n",
            "Epoch 2/200\n",
            "2286/2286 [==============================] - 670s 293ms/step - loss: 1.3789 - accuracy: 0.6260 - val_loss: 1.1157 - val_accuracy: 0.6731\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.38533 to 1.11569, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER5_epoch_002_val_1.116_accuracy_0.673.h5\n",
            "Epoch 3/200\n",
            "2286/2286 [==============================] - 658s 288ms/step - loss: 1.0595 - accuracy: 0.6994 - val_loss: 1.1812 - val_accuracy: 0.6859\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.11569\n",
            "Epoch 4/200\n",
            "2286/2286 [==============================] - 678s 296ms/step - loss: 0.8973 - accuracy: 0.7414 - val_loss: 0.9359 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.11569 to 0.93586, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER5_epoch_004_val_0.936_accuracy_0.718.h5\n",
            "Epoch 5/200\n",
            "2286/2286 [==============================] - 690s 302ms/step - loss: 0.7185 - accuracy: 0.7912 - val_loss: 0.8680 - val_accuracy: 0.7468\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.93586 to 0.86800, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER5_epoch_005_val_0.868_accuracy_0.747.h5\n",
            "Epoch 6/200\n",
            "2286/2286 [==============================] - 697s 305ms/step - loss: 0.6713 - accuracy: 0.8033 - val_loss: 0.9377 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.86800\n",
            "Epoch 7/200\n",
            "2286/2286 [==============================] - 691s 302ms/step - loss: 0.5416 - accuracy: 0.8416 - val_loss: 0.9553 - val_accuracy: 0.7564\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.86800\n",
            "Epoch 8/200\n",
            "2286/2286 [==============================] - 694s 304ms/step - loss: 0.4589 - accuracy: 0.8615 - val_loss: 0.8409 - val_accuracy: 0.7756\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.86800 to 0.84089, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER5_epoch_008_val_0.841_accuracy_0.776.h5\n",
            "Epoch 9/200\n",
            "2286/2286 [==============================] - 698s 305ms/step - loss: 0.4139 - accuracy: 0.8760 - val_loss: 0.9415 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.84089\n",
            "Epoch 10/200\n",
            "2286/2286 [==============================] - 699s 306ms/step - loss: 0.3694 - accuracy: 0.8886 - val_loss: 0.8884 - val_accuracy: 0.7885\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.84089\n",
            "Epoch 11/200\n",
            "2286/2286 [==============================] - 696s 304ms/step - loss: 0.3263 - accuracy: 0.9013 - val_loss: 0.9206 - val_accuracy: 0.7596\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.84089\n",
            "Epoch 12/200\n",
            "2286/2286 [==============================] - 688s 301ms/step - loss: 0.2893 - accuracy: 0.9121 - val_loss: 0.8738 - val_accuracy: 0.7821\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.84089\n",
            "Epoch 13/200\n",
            "2286/2286 [==============================] - 693s 303ms/step - loss: 0.2549 - accuracy: 0.9229 - val_loss: 0.8795 - val_accuracy: 0.7788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2813 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.84089\n",
            "... Validating on fold 7 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:05<00:00, 477.88it/s]\n",
            "  1%|          | 793/73138 [00:00<00:09, 7927.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73138, 600, 6) (73138,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73138/73138 [00:10<00:00, 7274.87it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 9667.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2286/2286 [==============================] - 731s 309ms/step - loss: 2.2488 - accuracy: 0.5065 - val_loss: 1.2623 - val_accuracy: 0.6442\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.26229, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER5_epoch_001_val_1.262_accuracy_0.644.h5\n",
            "Epoch 2/200\n",
            "2286/2286 [==============================] - 696s 305ms/step - loss: 1.2917 - accuracy: 0.6484 - val_loss: 1.1195 - val_accuracy: 0.6603\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.26229 to 1.11950, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER5_epoch_002_val_1.119_accuracy_0.660.h5\n",
            "Epoch 3/200\n",
            "2286/2286 [==============================] - 691s 302ms/step - loss: 0.9897 - accuracy: 0.7197 - val_loss: 1.0617 - val_accuracy: 0.6891\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.11950 to 1.06174, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER5_epoch_003_val_1.062_accuracy_0.689.h5\n",
            "Epoch 4/200\n",
            "2286/2286 [==============================] - 693s 303ms/step - loss: 0.8139 - accuracy: 0.7654 - val_loss: 0.9474 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.06174 to 0.94741, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER5_epoch_004_val_0.947_accuracy_0.724.h5\n",
            "Epoch 5/200\n",
            "2286/2286 [==============================] - 698s 305ms/step - loss: 0.6709 - accuracy: 0.8015 - val_loss: 0.9595 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.94741\n",
            "Epoch 6/200\n",
            "2286/2286 [==============================] - 699s 306ms/step - loss: 0.5291 - accuracy: 0.8426 - val_loss: 0.9447 - val_accuracy: 0.7468\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.94741 to 0.94470, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER5_epoch_006_val_0.945_accuracy_0.747.h5\n",
            "Epoch 7/200\n",
            "2286/2286 [==============================] - 704s 308ms/step - loss: 0.4531 - accuracy: 0.8644 - val_loss: 1.0769 - val_accuracy: 0.7115\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.94470\n",
            "Epoch 8/200\n",
            "2286/2286 [==============================] - 697s 305ms/step - loss: 0.3914 - accuracy: 0.8829 - val_loss: 1.0395 - val_accuracy: 0.7372\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.94470\n",
            "Epoch 9/200\n",
            "2286/2286 [==============================] - 686s 300ms/step - loss: 0.3285 - accuracy: 0.9011 - val_loss: 1.1697 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.94470\n",
            "Epoch 10/200\n",
            "2286/2286 [==============================] - 684s 299ms/step - loss: 0.2713 - accuracy: 0.9178 - val_loss: 1.1900 - val_accuracy: 0.7628\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.94470\n",
            "Epoch 11/200\n",
            "2286/2286 [==============================] - 689s 302ms/step - loss: 0.2353 - accuracy: 0.9267 - val_loss: 1.1584 - val_accuracy: 0.7468\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.94470\n",
            "... Validating on fold 8 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 50/2813 [00:00<00:05, 494.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 464.83it/s]\n",
            "  1%|          | 731/73138 [00:00<00:09, 7304.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73138, 600, 6) (73138,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73138/73138 [00:10<00:00, 7100.34it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 9291.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2286/2286 [==============================] - 711s 300ms/step - loss: 2.2195 - accuracy: 0.5132 - val_loss: 1.4089 - val_accuracy: 0.6090\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.40885, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER5_epoch_001_val_1.409_accuracy_0.609.h5\n",
            "Epoch 2/200\n",
            "2286/2286 [==============================] - 686s 300ms/step - loss: 1.2690 - accuracy: 0.6542 - val_loss: 0.9887 - val_accuracy: 0.7468\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.40885 to 0.98871, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER5_epoch_002_val_0.989_accuracy_0.747.h5\n",
            "Epoch 3/200\n",
            "2286/2286 [==============================] - 692s 303ms/step - loss: 0.9558 - accuracy: 0.7280 - val_loss: 0.8528 - val_accuracy: 0.7564\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.98871 to 0.85280, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER5_epoch_003_val_0.853_accuracy_0.756.h5\n",
            "Epoch 4/200\n",
            "2286/2286 [==============================] - 666s 291ms/step - loss: 0.7696 - accuracy: 0.7756 - val_loss: 0.9048 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.85280\n",
            "Epoch 5/200\n",
            "2286/2286 [==============================] - 671s 293ms/step - loss: 0.6049 - accuracy: 0.8233 - val_loss: 0.8440 - val_accuracy: 0.7981\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.85280 to 0.84395, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER5_epoch_005_val_0.844_accuracy_0.798.h5\n",
            "Epoch 6/200\n",
            "2286/2286 [==============================] - 686s 300ms/step - loss: 0.5048 - accuracy: 0.8509 - val_loss: 0.8425 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.84395 to 0.84250, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER5_epoch_006_val_0.843_accuracy_0.769.h5\n",
            "Epoch 7/200\n",
            "2286/2286 [==============================] - 700s 306ms/step - loss: 0.4612 - accuracy: 0.8614 - val_loss: 0.8073 - val_accuracy: 0.7949\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.84250 to 0.80734, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER5_epoch_007_val_0.807_accuracy_0.795.h5\n",
            "Epoch 8/200\n",
            "2286/2286 [==============================] - 702s 307ms/step - loss: 0.4157 - accuracy: 0.8738 - val_loss: 0.8721 - val_accuracy: 0.7885\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.80734\n",
            "Epoch 9/200\n",
            "2286/2286 [==============================] - 699s 306ms/step - loss: 0.3574 - accuracy: 0.8910 - val_loss: 0.9234 - val_accuracy: 0.7853\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.80734\n",
            "Epoch 10/200\n",
            "2286/2286 [==============================] - 698s 306ms/step - loss: 0.2998 - accuracy: 0.9093 - val_loss: 0.9080 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.80734\n",
            "Epoch 11/200\n",
            "2286/2286 [==============================] - 687s 301ms/step - loss: 0.2487 - accuracy: 0.9225 - val_loss: 0.9536 - val_accuracy: 0.7724\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.80734\n",
            "Epoch 12/200\n",
            "2286/2286 [==============================] - 695s 304ms/step - loss: 0.2193 - accuracy: 0.9322 - val_loss: 1.0284 - val_accuracy: 0.7885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2813 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.80734\n",
            "... Validating on fold 9 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 468.50it/s]\n",
            "  1%|          | 897/73138 [00:00<00:08, 8963.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73138, 600, 6) (73138,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73138/73138 [00:09<00:00, 7377.36it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 8566.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2286/2286 [==============================] - 721s 304ms/step - loss: 2.2662 - accuracy: 0.5047 - val_loss: 1.4495 - val_accuracy: 0.6442\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.44951, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_001_val_1.450_accuracy_0.644.h5\n",
            "Epoch 2/200\n",
            "2286/2286 [==============================] - 700s 306ms/step - loss: 1.2638 - accuracy: 0.6536 - val_loss: 1.1111 - val_accuracy: 0.7276\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.44951 to 1.11108, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_002_val_1.111_accuracy_0.728.h5\n",
            "Epoch 3/200\n",
            "2286/2286 [==============================] - 703s 308ms/step - loss: 0.9289 - accuracy: 0.7312 - val_loss: 1.0489 - val_accuracy: 0.7468\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.11108 to 1.04892, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_003_val_1.049_accuracy_0.747.h5\n",
            "Epoch 4/200\n",
            "2286/2286 [==============================] - 706s 309ms/step - loss: 0.7785 - accuracy: 0.7708 - val_loss: 0.9526 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.04892 to 0.95262, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_004_val_0.953_accuracy_0.750.h5\n",
            "Epoch 5/200\n",
            "1112/2286 [=============>................] - ETA: 6:02 - loss: 0.6385 - accuracy: 0.8133"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GS6DmuP9qyo"
      },
      "source": [
        "## Make prediction\n",
        "model1 = load_model('drive/MyDrive/movement_detection/kfold1/testNoise_epoch_004_val_0.905_accuracy_0.757.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model2 = load_model('drive/MyDrive/movement_detection/kfold2/testNoise_epoch_002_val_1.010_accuracy_0.725.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model3 = load_model('drive/MyDrive/movement_detection/kfold3/testNoise_epoch_004_val_0.957_accuracy_0.751.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})  \n",
        "model4 = load_model('drive/MyDrive/movement_detection/kfold4/testNoise_epoch_002_val_0.994_accuracy_0.709.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model5 = load_model('drive/MyDrive/movement_detection/kfold5/testNoise_epoch_004_val_0.966_accuracy_0.748.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model6 = load_model('drive/MyDrive/movement_detection/kfold6/testNoise_epoch_004_val_0.854_accuracy_0.772.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model7 = load_model('drive/MyDrive/movement_detection/kfold7/testNoise_epoch_003_val_1.004_accuracy_0.731.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model8 = load_model('drive/MyDrive/movement_detection/kfold8/testNoise_epoch_004_val_0.859_accuracy_0.763.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model9 = load_model('drive/MyDrive/movement_detection/kfold9/testNoise_epoch_002_val_1.107_accuracy_0.734.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model10 = load_model('drive/MyDrive/movement_detection/kfold10/testNoise_epoch_004_val_0.966_accuracy_0.763.h5',\n",
        "                     custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-phjrE01diZS"
      },
      "source": [
        "X_test = tf.reshape(np.array(test_features.iloc[:,2:]),[-1, 600, 6])\n",
        "X_test = np.asarray(X_test)\n",
        "\n",
        "##### feature engineering for test dataset ##### \n",
        "X_test_fourier_real = [] \n",
        "X_test_fourier_imag = [] \n",
        "for i in tqdm(range(X_test.shape[0]), position = 0, leave = True):\n",
        "    real_part = np.fft.fft(X_test[i]).real \n",
        "    imag_part = np.fft.fft(X_test[i]).imag \n",
        "    X_test_fourier_real.append(real_part) \n",
        "    X_test_fourier_imag.append(imag_part)\n",
        "    \n",
        "X_test_fourier_real = np.asarray(X_test_fourier_real) \n",
        "X_test_fourier_imag = np.asarray(X_test_fourier_imag)\n",
        "X_test = np.concatenate([X_test, X_test_fourier_real, X_test_fourier_imag], axis = 2)  \n",
        "\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5XLL0Xj-pNn"
      },
      "source": [
        "p1 = model1.predict(X_test) \n",
        "p2 = model2.predict(X_test)\n",
        "p3 = model3.predict(X_test) \n",
        "p4 = model4.predict(X_test) \n",
        "p5 = model5.predict(X_test) \n",
        "p6 = model6.predict(X_test) \n",
        "p7 = model7.predict(X_test) \n",
        "p8 = model8.predict(X_test)\n",
        "p9 = model9.predict(X_test)\n",
        "p10 = model10.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ee0ILAM-vAJ"
      },
      "source": [
        "p_avg = (p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + p10)/10.0\n",
        "\n",
        "sample_submission.iloc[:,1:] = p_avg\n",
        "\n",
        "sample_submission.to_csv(\"drive/MyDrive/movement_detection/TRANSFORMER5.csv\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}