{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRANSFORMER 4.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DassPRausTSg",
        "outputId": "6ea1ea78-6945-4f3a-b1e3-2ad1efac0236"
      },
      "source": [
        "pip install tsaug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tsaug in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from tsaug) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from tsaug) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnNG6A8JxJHh"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os, datetime \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *  \n",
        "from tensorflow.keras.callbacks import *\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold \n",
        "from tqdm import tqdm\n",
        "import random \n",
        "import time\n",
        "import pywt\n",
        "import tsaug\n",
        "from tsaug import TimeWarp, Crop, Quantize, Drift, Reverse "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJAFSSeCxLtQ"
      },
      "source": [
        "## Load data \n",
        "train_features = pd.read_csv('drive/MyDrive/movement_detection/train_features.csv')\n",
        "train_labels = pd.read_csv('drive/MyDrive/movement_detection/train_labels.csv')\n",
        "test_features = pd.read_csv('drive/MyDrive/movement_detection/test_features.csv')\n",
        "sample_submission = pd.read_csv('drive/MyDrive/movement_detection/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wYp4Ja5zbjU",
        "outputId": "23e3c8d6-7120-4685-977a-60e5e9046c5c"
      },
      "source": [
        "X = tf.reshape(np.array(train_features.iloc[:,2:]),[-1, 600, 6])\n",
        "X = np.asarray(X) \n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3125, 600, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keWlIAu_xThP",
        "outputId": "3ab4439a-b60d-4b37-c057-a7ef6d48d925"
      },
      "source": [
        "y = train_labels['label'].values\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3125,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2IuT7vhxVaF"
      },
      "source": [
        "batch_size = 32\n",
        "seq_len = 600 # temporary \n",
        "d_k = 256 \n",
        "d_v = 256\n",
        "n_heads = 12 \n",
        "ff_dim = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVb-3X5qxaIn"
      },
      "source": [
        "class SingleAttention(Layer):\n",
        "    def __init__(self, d_k, d_v):\n",
        "        super(SingleAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.query = Dense(self.d_k, \n",
        "                       input_shape=input_shape, \n",
        "                       kernel_initializer='glorot_uniform', \n",
        "                       bias_initializer='glorot_uniform')\n",
        "    \n",
        "        self.key = Dense(self.d_k, \n",
        "                     input_shape=input_shape, \n",
        "                     kernel_initializer='glorot_uniform', \n",
        "                     bias_initializer='glorot_uniform')\n",
        "    \n",
        "        self.value = Dense(self.d_v, \n",
        "                       input_shape=input_shape, \n",
        "                       kernel_initializer='glorot_uniform', \n",
        "                       bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "        q = self.query(inputs[0])\n",
        "        k = self.key(inputs[1])\n",
        "\n",
        "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
        "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
        "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
        "    \n",
        "        v = self.value(inputs[2])\n",
        "        attn_out = tf.matmul(attn_weights, v)\n",
        "        return attn_out    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99TiWqeFxb7I"
      },
      "source": [
        "class MultiAttention(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads):\n",
        "        super(MultiAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.attn_heads = list()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        for n in range(self.n_heads):\n",
        "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
        "    \n",
        "        self.linear = Dense(input_shape[0][-1], \n",
        "                        input_shape=input_shape, \n",
        "                        kernel_initializer='glorot_uniform', \n",
        "                        bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
        "        concat_attn = tf.concat(attn, axis=-1)\n",
        "        multi_linear = self.linear(concat_attn)\n",
        "        return multi_linear   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3414BzYQx5_R"
      },
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.attn_heads = []\n",
        "        self.dropout_rate = dropout \n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
        "        self.attn_dropout = Dropout(self.dropout_rate)\n",
        "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
        "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
        "        self.ff_dropout = Dropout(self.dropout_rate)\n",
        "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
        "  \n",
        "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq) \n",
        "        attn_layer = self.attn_multi(inputs) \n",
        "        attn_layer = self.attn_dropout(attn_layer)\n",
        "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
        "        ff_layer = self.ff_conv1D_1(attn_layer)  \n",
        "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
        "        ff_layer = self.ff_dropout(ff_layer)\n",
        "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
        "        return ff_layer \n",
        "\n",
        "    def get_config(self): # Needed for saving and loading model with custom layer\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'d_k': self.d_k,\n",
        "                   'd_v': self.d_v,\n",
        "                   'n_heads': self.n_heads,\n",
        "                   'ff_dim': self.ff_dim,\n",
        "                   'attn_heads': self.attn_heads,\n",
        "                   'dropout_rate': self.dropout_rate})\n",
        "        return config\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT5EKjBWx8cq"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HlyWyhWx_Y5"
      },
      "source": [
        "def build_model(seq_len, features): \n",
        "  inputs = Input(shape=(seq_len,features))   \n",
        "  bn = BatchNormalization()(inputs)    \n",
        "\n",
        "  conv = Conv1D(256, 5, activation = 'relu', padding = 'same')(bn) \n",
        "  bn = BatchNormalization()(conv) \n",
        "  maxpool = MaxPooling1D()(bn) \n",
        "  conv = Conv1D(256, 5, activation = 'relu', padding = 'same')(maxpool) \n",
        "  bn = BatchNormalization()(conv) \n",
        "  features = MaxPooling1D()(bn) \n",
        "\n",
        "  pos_encoding = positional_encoding(seq_len, d_k)    \n",
        "  features *= tf.math.sqrt(tf.cast(d_k, tf.float32)) # scale  \n",
        "  features += pos_encoding[:, :features.shape[1], :] # add positional encoding \n",
        "\n",
        "  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "\n",
        "  x = attn_layer1((features, features, features))   \n",
        "  x = attn_layer2((x, x, x)) \n",
        "  x = attn_layer3((x, x, x)) \n",
        "\n",
        "  bi_gru = Bidirectional(GRU(128, return_sequences = False))(x) \n",
        "  dropout = Dropout(0.25)(bi_gru) \n",
        "  dense = Dense(128, activation = 'relu')(dropout) \n",
        "  bn = BatchNormalization()(dense) \n",
        "  outputs = Dense(61, activation='softmax')(bn) \n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E24-11j9yBAq",
        "outputId": "11f3902c-d267-41af-d867-3a5c15e60141"
      },
      "source": [
        "model = build_model(600,18)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 600, 18)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 600, 18)      72          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 600, 256)     23296       batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 600, 256)     1024        conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 300, 256)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 300, 256)     327936      max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 300, 256)     1024        conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 150, 256)     0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply (TFOpLambda)   (None, 150, 256)     0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 150, 256)     0           tf.math.multiply[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder (Transforme (None, 150, 256)     3419136     tf.__operators__.add[0][0]       \n",
            "                                                                 tf.__operators__.add[0][0]       \n",
            "                                                                 tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_1 (Transfor (None, 150, 256)     3419136     transformer_encoder[0][0]        \n",
            "                                                                 transformer_encoder[0][0]        \n",
            "                                                                 transformer_encoder[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_2 (Transfor (None, 150, 256)     3419136     transformer_encoder_1[0][0]      \n",
            "                                                                 transformer_encoder_1[0][0]      \n",
            "                                                                 transformer_encoder_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 256)          296448      transformer_encoder_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 256)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          32896       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128)          512         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 61)           7869        batch_normalization_3[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 10,948,485\n",
            "Trainable params: 10,947,169\n",
            "Non-trainable params: 1,316\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL1SddNoyCaI",
        "outputId": "c7f0544e-7b06-4c6f-f406-63917c4505d7"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits = 10, random_state = 960418, shuffle = True)\n",
        "for idx,(train_idx, val_idx) in enumerate(kfold.split(X,y)):   \n",
        "    print(\"... Validating on fold {} ...\".format(idx+1))  \n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx] \n",
        "    \n",
        "    ##### augment data #####\n",
        "    print(\"... Augmenting Data ...\")\n",
        "    X_augmented = [] \n",
        "    y_augmented = [] \n",
        "\n",
        "    for i in tqdm(range(X_train.shape[0]), position = 0, leave = True): \n",
        "        for j in range(10): # add random shift \n",
        "            shifted = np.roll(X_train[i], int(random.random() * 600)) \n",
        "            X_augmented.append(shifted) \n",
        "            y_augmented.append(y_train[i]) \n",
        "        for j in range(10): # add noise \n",
        "            noised = np.random.normal(0, 1, X_train[i].shape) + X_train[i] \n",
        "            X_augmented.append(noised) \n",
        "            y_augmented.append(y_train[i])   \n",
        "    \n",
        "\n",
        "    X_cropped = Crop(random.randint(300, 580), resize = 600).augment(X_train) \n",
        "    X_warped = TimeWarp(random.randint(3,20)).augment(X_train)  \n",
        "    X_reversed = Reverse().augment(X_train) \n",
        "    X_quantized = Quantize(random.randint(10,100)).augment(X_train)\n",
        "    \n",
        "    X_augmented = np.asarray(X_augmented) \n",
        "    y_augmented = np.asarray(y_augmented)    \n",
        "\n",
        "    X_train = np.concatenate([X_train, X_augmented, X_cropped, X_warped, X_reversed, X_quantized]) \n",
        "    y_train = np.concatenate([y_train, y_augmented, y_train, y_train, y_train, y_train])  \n",
        "\n",
        "    print(\"Train shapes\")\n",
        "    print(X_train.shape, y_train.shape)  \n",
        "\n",
        "    ###### feature engineering data ##### \n",
        "    print(\"... DFFT Feature Engineering ...\")\n",
        "    X_fourier_real = [] \n",
        "    X_fourier_imag = [] \n",
        "    for i in tqdm(range(X_train.shape[0]), position = 0, leave = True):  \n",
        "        real_part = np.fft.fft(X_train[i]).real \n",
        "        imag_part = np.fft.fft(X_train[i]).imag \n",
        "        X_fourier_real.append(real_part)\n",
        "        X_fourier_imag.append(imag_part) \n",
        "    \n",
        "    X_fourier_real = np.asarray(X_fourier_real)  \n",
        "    X_fourier_imag = np.asarray(X_fourier_imag)\n",
        "    \n",
        "    \n",
        "    X_val_fourier_real = [] \n",
        "    X_val_fourier_imag = [] \n",
        "    for i in tqdm(range(X_val.shape[0]), position = 0, leave = True):\n",
        "        real_part = np.fft.fft(X_val[i]).real \n",
        "        imag_part = np.fft.fft(X_val[i]).imag \n",
        "        X_val_fourier_real.append(real_part) \n",
        "        X_val_fourier_imag.append(imag_part)\n",
        "    \n",
        "    X_val_fourier_real = np.asarray(X_val_fourier_real) \n",
        "    X_val_fourier_imag = np.asarray(X_val_fourier_imag)\n",
        "    \n",
        "    X_train = np.concatenate([X_train, X_fourier_real, X_fourier_imag], axis = 2)  \n",
        "    X_val = np.concatenate([X_val, X_val_fourier_real, X_val_fourier_imag], axis = 2)\n",
        "\n",
        "    ##### train model #####  \n",
        "    print(\"... Building Model ...\")\n",
        "    # we have 18 features after feature engineering \n",
        "    model = build_model(600, 18) \n",
        "    print(\"... Training ...\") \n",
        "    model_path = 'drive/MyDrive/movement_detection/kfold' + str(idx+1) + '/TRANSFORMER4_epoch_{epoch:03d}_val_{val_loss:.3f}_accuracy_{val_accuracy:.3f}.h5'\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 1, verbose = 1, factor = 0.8)\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5) \n",
        "\n",
        "    model.fit(X_train,\n",
        "              y_train,\n",
        "              epochs = 200,\n",
        "              batch_size = 32, # hyperparameter  \n",
        "              validation_data = (X_val, y_val), \n",
        "              callbacks = [learning_rate_reduction, checkpoint, early_stopping])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2812 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Validating on fold 1 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:05<00:00, 472.87it/s]\n",
            "  1%|▏         | 973/70300 [00:00<00:07, 9729.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70300, 600, 6) (70300,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70300/70300 [00:09<00:00, 7748.64it/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 10155.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2197/2197 [==============================] - 648s 282ms/step - loss: 2.2310 - accuracy: 0.5116 - val_loss: 1.6651 - val_accuracy: 0.5655\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.66506, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER4_epoch_001_val_1.665_accuracy_0.565.h5\n",
            "Epoch 2/200\n",
            "2197/2197 [==============================] - 615s 280ms/step - loss: 1.4305 - accuracy: 0.6098 - val_loss: 1.1998 - val_accuracy: 0.7061\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.66506 to 1.19977, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER4_epoch_002_val_1.200_accuracy_0.706.h5\n",
            "Epoch 3/200\n",
            "2197/2197 [==============================] - 620s 282ms/step - loss: 1.0588 - accuracy: 0.6988 - val_loss: 0.9487 - val_accuracy: 0.7316\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.19977 to 0.94869, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER4_epoch_003_val_0.949_accuracy_0.732.h5\n",
            "Epoch 4/200\n",
            "2197/2197 [==============================] - 616s 281ms/step - loss: 0.8708 - accuracy: 0.7478 - val_loss: 0.9322 - val_accuracy: 0.7220\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.94869 to 0.93222, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER4_epoch_004_val_0.932_accuracy_0.722.h5\n",
            "Epoch 5/200\n",
            "2197/2197 [==============================] - 614s 280ms/step - loss: 0.7362 - accuracy: 0.7852 - val_loss: 0.9444 - val_accuracy: 0.7604\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.93222\n",
            "Epoch 6/200\n",
            "2197/2197 [==============================] - 615s 280ms/step - loss: 0.5864 - accuracy: 0.8280 - val_loss: 0.8594 - val_accuracy: 0.7827\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.93222 to 0.85939, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER4_epoch_006_val_0.859_accuracy_0.783.h5\n",
            "Epoch 7/200\n",
            "2197/2197 [==============================] - 613s 279ms/step - loss: 0.5246 - accuracy: 0.8449 - val_loss: 0.9212 - val_accuracy: 0.7316\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.85939\n",
            "Epoch 8/200\n",
            "2197/2197 [==============================] - 614s 280ms/step - loss: 0.4375 - accuracy: 0.8729 - val_loss: 0.8539 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.85939 to 0.85394, saving model to drive/MyDrive/movement_detection/kfold1/TRANSFORMER4_epoch_008_val_0.854_accuracy_0.770.h5\n",
            "Epoch 9/200\n",
            "2197/2197 [==============================] - 619s 282ms/step - loss: 0.3981 - accuracy: 0.8820 - val_loss: 0.9997 - val_accuracy: 0.7444\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.85394\n",
            "Epoch 10/200\n",
            "2197/2197 [==============================] - 616s 280ms/step - loss: 0.3424 - accuracy: 0.8964 - val_loss: 0.9655 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.85394\n",
            "Epoch 11/200\n",
            "2197/2197 [==============================] - 615s 280ms/step - loss: 0.2927 - accuracy: 0.9101 - val_loss: 0.9203 - val_accuracy: 0.7636\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.85394\n",
            "Epoch 12/200\n",
            "2197/2197 [==============================] - 617s 281ms/step - loss: 0.2544 - accuracy: 0.9229 - val_loss: 0.9917 - val_accuracy: 0.7540\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.85394\n",
            "Epoch 13/200\n",
            "2197/2197 [==============================] - 621s 283ms/step - loss: 0.2267 - accuracy: 0.9320 - val_loss: 0.9468 - val_accuracy: 0.7700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 50/2812 [00:00<00:05, 496.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.85394\n",
            "... Validating on fold 2 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:05<00:00, 470.53it/s]\n",
            "  1%|▏         | 927/70300 [00:00<00:07, 9267.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70300, 600, 6) (70300,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70300/70300 [00:08<00:00, 8522.60it/s] \n",
            "100%|██████████| 313/313 [00:00<00:00, 9689.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2197/2197 [==============================] - 658s 288ms/step - loss: 2.2132 - accuracy: 0.5116 - val_loss: 1.4347 - val_accuracy: 0.6294\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.43471, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER4_epoch_001_val_1.435_accuracy_0.629.h5\n",
            "Epoch 2/200\n",
            "2197/2197 [==============================] - 628s 286ms/step - loss: 1.3397 - accuracy: 0.6287 - val_loss: 1.2346 - val_accuracy: 0.6518\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.43471 to 1.23461, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER4_epoch_002_val_1.235_accuracy_0.652.h5\n",
            "Epoch 3/200\n",
            "2197/2197 [==============================] - 620s 282ms/step - loss: 0.9680 - accuracy: 0.7163 - val_loss: 1.0943 - val_accuracy: 0.7125\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.23461 to 1.09433, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER4_epoch_003_val_1.094_accuracy_0.712.h5\n",
            "Epoch 4/200\n",
            "2197/2197 [==============================] - 623s 284ms/step - loss: 0.7986 - accuracy: 0.7682 - val_loss: 1.0502 - val_accuracy: 0.7348\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.09433 to 1.05020, saving model to drive/MyDrive/movement_detection/kfold2/TRANSFORMER4_epoch_004_val_1.050_accuracy_0.735.h5\n",
            "Epoch 5/200\n",
            "2197/2197 [==============================] - 621s 283ms/step - loss: 0.6318 - accuracy: 0.8113 - val_loss: 1.0711 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.05020\n",
            "Epoch 6/200\n",
            "2197/2197 [==============================] - 623s 284ms/step - loss: 0.5129 - accuracy: 0.8503 - val_loss: 1.1740 - val_accuracy: 0.7316\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.05020\n",
            "Epoch 7/200\n",
            "2197/2197 [==============================] - 626s 285ms/step - loss: 0.4226 - accuracy: 0.8722 - val_loss: 1.1020 - val_accuracy: 0.7444\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.05020\n",
            "Epoch 8/200\n",
            "2197/2197 [==============================] - 624s 284ms/step - loss: 0.3463 - accuracy: 0.8978 - val_loss: 1.1689 - val_accuracy: 0.7284\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.05020\n",
            "Epoch 9/200\n",
            "2197/2197 [==============================] - 627s 286ms/step - loss: 0.3127 - accuracy: 0.9049 - val_loss: 1.1863 - val_accuracy: 0.7412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2812 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.05020\n",
            "... Validating on fold 3 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:06<00:00, 461.72it/s]\n",
            "  1%|▏         | 965/70300 [00:00<00:07, 9647.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70300, 600, 6) (70300,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70300/70300 [00:09<00:00, 7551.08it/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 9772.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2197/2197 [==============================] - 664s 290ms/step - loss: 2.2085 - accuracy: 0.5119 - val_loss: 1.4404 - val_accuracy: 0.6070\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.44043, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER4_epoch_001_val_1.440_accuracy_0.607.h5\n",
            "Epoch 2/200\n",
            "2197/2197 [==============================] - 633s 288ms/step - loss: 1.3068 - accuracy: 0.6382 - val_loss: 1.0182 - val_accuracy: 0.7093\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.44043 to 1.01816, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER4_epoch_002_val_1.018_accuracy_0.709.h5\n",
            "Epoch 3/200\n",
            "2197/2197 [==============================] - 642s 292ms/step - loss: 0.9740 - accuracy: 0.7189 - val_loss: 0.8865 - val_accuracy: 0.7348\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.01816 to 0.88654, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER4_epoch_003_val_0.887_accuracy_0.735.h5\n",
            "Epoch 4/200\n",
            "2197/2197 [==============================] - 644s 293ms/step - loss: 0.7558 - accuracy: 0.7784 - val_loss: 0.8593 - val_accuracy: 0.7252\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.88654 to 0.85932, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER4_epoch_004_val_0.859_accuracy_0.725.h5\n",
            "Epoch 5/200\n",
            "2197/2197 [==============================] - 646s 294ms/step - loss: 0.6190 - accuracy: 0.8149 - val_loss: 0.8354 - val_accuracy: 0.7444\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.85932 to 0.83538, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER4_epoch_005_val_0.835_accuracy_0.744.h5\n",
            "Epoch 6/200\n",
            "2197/2197 [==============================] - 644s 293ms/step - loss: 0.5444 - accuracy: 0.8389 - val_loss: 0.8047 - val_accuracy: 0.7796\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.83538 to 0.80469, saving model to drive/MyDrive/movement_detection/kfold3/TRANSFORMER4_epoch_006_val_0.805_accuracy_0.780.h5\n",
            "Epoch 7/200\n",
            "2197/2197 [==============================] - 641s 292ms/step - loss: 0.4855 - accuracy: 0.8545 - val_loss: 0.8314 - val_accuracy: 0.7636\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.80469\n",
            "Epoch 8/200\n",
            "2197/2197 [==============================] - 639s 291ms/step - loss: 0.4052 - accuracy: 0.8803 - val_loss: 0.8078 - val_accuracy: 0.7732\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.80469\n",
            "Epoch 9/200\n",
            "2197/2197 [==============================] - 637s 290ms/step - loss: 0.3326 - accuracy: 0.8982 - val_loss: 0.8056 - val_accuracy: 0.7668\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.80469\n",
            "Epoch 10/200\n",
            "2197/2197 [==============================] - 640s 291ms/step - loss: 0.2894 - accuracy: 0.9125 - val_loss: 0.8395 - val_accuracy: 0.7732\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.80469\n",
            "Epoch 11/200\n",
            "2197/2197 [==============================] - 636s 290ms/step - loss: 0.2482 - accuracy: 0.9258 - val_loss: 0.8667 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.80469\n",
            "... Validating on fold 4 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:05<00:00, 473.17it/s]\n",
            "  1%|▏         | 973/70300 [00:00<00:07, 9721.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70300, 600, 6) (70300,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70300/70300 [00:08<00:00, 8212.98it/s] \n",
            "100%|██████████| 313/313 [00:00<00:00, 9616.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2197/2197 [==============================] - 660s 289ms/step - loss: 2.2334 - accuracy: 0.5121 - val_loss: 1.3220 - val_accuracy: 0.6230\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.32202, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER4_epoch_001_val_1.322_accuracy_0.623.h5\n",
            "Epoch 2/200\n",
            "2197/2197 [==============================] - 630s 287ms/step - loss: 1.3278 - accuracy: 0.6344 - val_loss: 0.9922 - val_accuracy: 0.7316\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.32202 to 0.99221, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER4_epoch_002_val_0.992_accuracy_0.732.h5\n",
            "Epoch 3/200\n",
            "2197/2197 [==============================] - 633s 288ms/step - loss: 0.9552 - accuracy: 0.7224 - val_loss: 0.9739 - val_accuracy: 0.7444\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.99221 to 0.97393, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER4_epoch_003_val_0.974_accuracy_0.744.h5\n",
            "Epoch 4/200\n",
            "2197/2197 [==============================] - 628s 286ms/step - loss: 0.7291 - accuracy: 0.7848 - val_loss: 0.9315 - val_accuracy: 0.7476\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.97393 to 0.93148, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER4_epoch_004_val_0.931_accuracy_0.748.h5\n",
            "Epoch 5/200\n",
            "2197/2197 [==============================] - 622s 283ms/step - loss: 0.6674 - accuracy: 0.8007 - val_loss: 0.9507 - val_accuracy: 0.7444\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.93148\n",
            "Epoch 6/200\n",
            "2197/2197 [==============================] - 624s 284ms/step - loss: 0.4826 - accuracy: 0.8541 - val_loss: 0.8991 - val_accuracy: 0.7668\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.93148 to 0.89908, saving model to drive/MyDrive/movement_detection/kfold4/TRANSFORMER4_epoch_006_val_0.899_accuracy_0.767.h5\n",
            "Epoch 7/200\n",
            "2197/2197 [==============================] - 639s 291ms/step - loss: 0.4126 - accuracy: 0.8742 - val_loss: 0.9178 - val_accuracy: 0.7764\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.89908\n",
            "Epoch 8/200\n",
            "2197/2197 [==============================] - 645s 293ms/step - loss: 0.3446 - accuracy: 0.8968 - val_loss: 1.0048 - val_accuracy: 0.7732\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.89908\n",
            "Epoch 9/200\n",
            "2197/2197 [==============================] - 645s 293ms/step - loss: 0.2870 - accuracy: 0.9124 - val_loss: 1.0129 - val_accuracy: 0.7796\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.89908\n",
            "Epoch 10/200\n",
            "2197/2197 [==============================] - 644s 293ms/step - loss: 0.2340 - accuracy: 0.9284 - val_loss: 1.0430 - val_accuracy: 0.7764\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.89908\n",
            "Epoch 11/200\n",
            "2197/2197 [==============================] - 633s 288ms/step - loss: 0.2014 - accuracy: 0.9395 - val_loss: 1.0707 - val_accuracy: 0.7796\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.89908\n",
            "... Validating on fold 5 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 43/2812 [00:00<00:06, 429.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2812/2812 [00:05<00:00, 474.96it/s]\n",
            "  1%|▏         | 895/70300 [00:00<00:07, 8944.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70300, 600, 6) (70300,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70300/70300 [00:09<00:00, 7679.50it/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 9437.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2197/2197 [==============================] - 663s 291ms/step - loss: 2.1856 - accuracy: 0.5145 - val_loss: 1.4570 - val_accuracy: 0.5847\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.45701, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER4_epoch_001_val_1.457_accuracy_0.585.h5\n",
            "Epoch 2/200\n",
            "2197/2197 [==============================] - 633s 288ms/step - loss: 1.3306 - accuracy: 0.6298 - val_loss: 1.1328 - val_accuracy: 0.6933\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.45701 to 1.13285, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER4_epoch_002_val_1.133_accuracy_0.693.h5\n",
            "Epoch 3/200\n",
            "2197/2197 [==============================] - 636s 290ms/step - loss: 0.9986 - accuracy: 0.7140 - val_loss: 0.9305 - val_accuracy: 0.7348\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.13285 to 0.93050, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER4_epoch_003_val_0.931_accuracy_0.735.h5\n",
            "Epoch 4/200\n",
            "2197/2197 [==============================] - 654s 298ms/step - loss: 0.7701 - accuracy: 0.7735 - val_loss: 0.8334 - val_accuracy: 0.7604\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.93050 to 0.83338, saving model to drive/MyDrive/movement_detection/kfold5/TRANSFORMER4_epoch_004_val_0.833_accuracy_0.760.h5\n",
            "Epoch 5/200\n",
            "2197/2197 [==============================] - 654s 298ms/step - loss: 0.6222 - accuracy: 0.8160 - val_loss: 1.0395 - val_accuracy: 0.7316\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.83338\n",
            "Epoch 6/200\n",
            "2197/2197 [==============================] - 660s 300ms/step - loss: 0.5130 - accuracy: 0.8478 - val_loss: 0.9659 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.83338\n",
            "Epoch 7/200\n",
            "2197/2197 [==============================] - 661s 301ms/step - loss: 0.4130 - accuracy: 0.8752 - val_loss: 0.9159 - val_accuracy: 0.7572\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.83338\n",
            "Epoch 8/200\n",
            "2197/2197 [==============================] - 655s 298ms/step - loss: 0.3384 - accuracy: 0.8968 - val_loss: 1.0050 - val_accuracy: 0.7476\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.83338\n",
            "Epoch 9/200\n",
            "2197/2197 [==============================] - 663s 302ms/step - loss: 0.2979 - accuracy: 0.9091 - val_loss: 0.9937 - val_accuracy: 0.7508\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.83338\n",
            "... Validating on fold 6 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 48/2813 [00:00<00:05, 476.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 431.62it/s]\n",
            "  1%|          | 822/70325 [00:00<00:08, 8217.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70325, 600, 6) (70325,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70325/70325 [00:09<00:00, 7737.12it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 9486.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2198/2198 [==============================] - 688s 301ms/step - loss: 2.2100 - accuracy: 0.5154 - val_loss: 1.2941 - val_accuracy: 0.6603\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.29409, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER4_epoch_001_val_1.294_accuracy_0.660.h5\n",
            "Epoch 2/200\n",
            "2198/2198 [==============================] - 657s 299ms/step - loss: 1.3471 - accuracy: 0.6295 - val_loss: 1.0885 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.29409 to 1.08854, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER4_epoch_002_val_1.089_accuracy_0.708.h5\n",
            "Epoch 3/200\n",
            "2198/2198 [==============================] - 655s 298ms/step - loss: 0.9819 - accuracy: 0.7153 - val_loss: 0.9235 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.08854 to 0.92351, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER4_epoch_003_val_0.924_accuracy_0.724.h5\n",
            "Epoch 4/200\n",
            "2198/2198 [==============================] - 645s 293ms/step - loss: 0.7790 - accuracy: 0.7700 - val_loss: 0.8858 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.92351 to 0.88580, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER4_epoch_004_val_0.886_accuracy_0.750.h5\n",
            "Epoch 5/200\n",
            "2198/2198 [==============================] - 642s 292ms/step - loss: 0.6656 - accuracy: 0.8016 - val_loss: 0.8910 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.88580\n",
            "Epoch 6/200\n",
            "2198/2198 [==============================] - 645s 294ms/step - loss: 0.5280 - accuracy: 0.8430 - val_loss: 0.8003 - val_accuracy: 0.7853\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.88580 to 0.80029, saving model to drive/MyDrive/movement_detection/kfold6/TRANSFORMER4_epoch_006_val_0.800_accuracy_0.785.h5\n",
            "Epoch 7/200\n",
            "2198/2198 [==============================] - 637s 290ms/step - loss: 0.4651 - accuracy: 0.8615 - val_loss: 0.8844 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.80029\n",
            "Epoch 8/200\n",
            "2198/2198 [==============================] - 636s 289ms/step - loss: 0.3746 - accuracy: 0.8880 - val_loss: 0.8676 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.80029\n",
            "Epoch 9/200\n",
            "2198/2198 [==============================] - 632s 287ms/step - loss: 0.3104 - accuracy: 0.9051 - val_loss: 0.8993 - val_accuracy: 0.8013\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.80029\n",
            "Epoch 10/200\n",
            "2198/2198 [==============================] - 627s 285ms/step - loss: 0.2769 - accuracy: 0.9153 - val_loss: 0.8840 - val_accuracy: 0.7756\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.80029\n",
            "Epoch 11/200\n",
            "2198/2198 [==============================] - 632s 288ms/step - loss: 0.2333 - accuracy: 0.9266 - val_loss: 0.9609 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.80029\n",
            "... Validating on fold 7 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 51/2813 [00:00<00:05, 500.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 445.76it/s]\n",
            "  1%|▏         | 936/70325 [00:00<00:07, 9350.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70325, 600, 6) (70325,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70325/70325 [00:09<00:00, 7407.18it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 9147.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2198/2198 [==============================] - 669s 293ms/step - loss: 2.2357 - accuracy: 0.5129 - val_loss: 1.4147 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.41465, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER4_epoch_001_val_1.415_accuracy_0.583.h5\n",
            "Epoch 2/200\n",
            "2198/2198 [==============================] - 643s 293ms/step - loss: 1.2926 - accuracy: 0.6411 - val_loss: 1.1301 - val_accuracy: 0.6795\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.41465 to 1.13008, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER4_epoch_002_val_1.130_accuracy_0.679.h5\n",
            "Epoch 3/200\n",
            "2198/2198 [==============================] - 633s 288ms/step - loss: 0.9833 - accuracy: 0.7155 - val_loss: 1.0239 - val_accuracy: 0.7051\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.13008 to 1.02389, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER4_epoch_003_val_1.024_accuracy_0.705.h5\n",
            "Epoch 4/200\n",
            "2198/2198 [==============================] - 610s 278ms/step - loss: 0.7674 - accuracy: 0.7768 - val_loss: 1.0088 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.02389 to 1.00879, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER4_epoch_004_val_1.009_accuracy_0.740.h5\n",
            "Epoch 5/200\n",
            "2198/2198 [==============================] - 613s 279ms/step - loss: 0.6371 - accuracy: 0.8120 - val_loss: 0.9855 - val_accuracy: 0.7276\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.00879 to 0.98546, saving model to drive/MyDrive/movement_detection/kfold7/TRANSFORMER4_epoch_005_val_0.985_accuracy_0.728.h5\n",
            "Epoch 6/200\n",
            "2198/2198 [==============================] - 631s 287ms/step - loss: 0.5530 - accuracy: 0.8351 - val_loss: 1.0103 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.98546\n",
            "Epoch 7/200\n",
            "2198/2198 [==============================] - 642s 292ms/step - loss: 0.4227 - accuracy: 0.8738 - val_loss: 1.0722 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.98546\n",
            "Epoch 8/200\n",
            "2198/2198 [==============================] - 630s 287ms/step - loss: 0.3521 - accuracy: 0.8931 - val_loss: 1.0925 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.98546\n",
            "Epoch 9/200\n",
            "2198/2198 [==============================] - 625s 284ms/step - loss: 0.2867 - accuracy: 0.9144 - val_loss: 1.0645 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.98546\n",
            "Epoch 10/200\n",
            "2198/2198 [==============================] - 638s 290ms/step - loss: 0.2463 - accuracy: 0.9241 - val_loss: 1.2110 - val_accuracy: 0.7436\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.98546\n",
            "... Validating on fold 8 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 52/2813 [00:00<00:05, 519.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 463.67it/s]\n",
            "  1%|▏         | 926/70325 [00:00<00:07, 9254.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70325, 600, 6) (70325,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70325/70325 [00:09<00:00, 7393.76it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 9600.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2198/2198 [==============================] - 665s 291ms/step - loss: 2.1887 - accuracy: 0.5122 - val_loss: 1.2317 - val_accuracy: 0.6699\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23170, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER4_epoch_001_val_1.232_accuracy_0.670.h5\n",
            "Epoch 2/200\n",
            "2198/2198 [==============================] - 642s 292ms/step - loss: 1.2989 - accuracy: 0.6429 - val_loss: 0.9641 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23170 to 0.96408, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER4_epoch_002_val_0.964_accuracy_0.724.h5\n",
            "Epoch 3/200\n",
            "2198/2198 [==============================] - 640s 291ms/step - loss: 0.9724 - accuracy: 0.7253 - val_loss: 0.9151 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.96408 to 0.91505, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER4_epoch_003_val_0.915_accuracy_0.740.h5\n",
            "Epoch 4/200\n",
            "2198/2198 [==============================] - 638s 290ms/step - loss: 0.8373 - accuracy: 0.7605 - val_loss: 0.8270 - val_accuracy: 0.7628\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.91505 to 0.82697, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER4_epoch_004_val_0.827_accuracy_0.763.h5\n",
            "Epoch 5/200\n",
            "2198/2198 [==============================] - 636s 289ms/step - loss: 0.7053 - accuracy: 0.7919 - val_loss: 0.8170 - val_accuracy: 0.7724\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.82697 to 0.81699, saving model to drive/MyDrive/movement_detection/kfold8/TRANSFORMER4_epoch_005_val_0.817_accuracy_0.772.h5\n",
            "Epoch 6/200\n",
            "2198/2198 [==============================] - 623s 284ms/step - loss: 0.5975 - accuracy: 0.8232 - val_loss: 0.8615 - val_accuracy: 0.7372\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.81699\n",
            "Epoch 7/200\n",
            "2198/2198 [==============================] - 620s 282ms/step - loss: 0.5276 - accuracy: 0.8454 - val_loss: 0.8593 - val_accuracy: 0.7756\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.81699\n",
            "Epoch 8/200\n",
            "2198/2198 [==============================] - 624s 284ms/step - loss: 0.4368 - accuracy: 0.8686 - val_loss: 0.8649 - val_accuracy: 0.7596\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.81699\n",
            "Epoch 9/200\n",
            "2198/2198 [==============================] - 635s 289ms/step - loss: 0.3643 - accuracy: 0.8921 - val_loss: 0.9005 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.81699\n",
            "Epoch 10/200\n",
            "2198/2198 [==============================] - 652s 297ms/step - loss: 0.3213 - accuracy: 0.9032 - val_loss: 0.8844 - val_accuracy: 0.7628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2813 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.81699\n",
            "... Validating on fold 9 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 459.26it/s]\n",
            "  1%|▏         | 970/70325 [00:00<00:07, 9691.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70325, 600, 6) (70325,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70325/70325 [00:09<00:00, 7486.37it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 9502.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2198/2198 [==============================] - 681s 298ms/step - loss: 2.2533 - accuracy: 0.5075 - val_loss: 1.3988 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.39879, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER4_epoch_001_val_1.399_accuracy_0.615.h5\n",
            "Epoch 2/200\n",
            "2198/2198 [==============================] - 655s 298ms/step - loss: 1.3618 - accuracy: 0.6234 - val_loss: 1.2263 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.39879 to 1.22628, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER4_epoch_002_val_1.226_accuracy_0.708.h5\n",
            "Epoch 3/200\n",
            "2198/2198 [==============================] - 656s 298ms/step - loss: 1.0272 - accuracy: 0.7052 - val_loss: 0.9918 - val_accuracy: 0.7468\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.22628 to 0.99178, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER4_epoch_003_val_0.992_accuracy_0.747.h5\n",
            "Epoch 4/200\n",
            "2198/2198 [==============================] - 660s 300ms/step - loss: 0.8387 - accuracy: 0.7515 - val_loss: 1.0110 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.99178\n",
            "Epoch 5/200\n",
            "2198/2198 [==============================] - 652s 297ms/step - loss: 0.6586 - accuracy: 0.8082 - val_loss: 0.9835 - val_accuracy: 0.7724\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.99178 to 0.98354, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER4_epoch_005_val_0.984_accuracy_0.772.h5\n",
            "Epoch 6/200\n",
            "2198/2198 [==============================] - 643s 293ms/step - loss: 0.5448 - accuracy: 0.8360 - val_loss: 0.9725 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.98354 to 0.97248, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER4_epoch_006_val_0.972_accuracy_0.779.h5\n",
            "Epoch 7/200\n",
            "2198/2198 [==============================] - 657s 299ms/step - loss: 0.4870 - accuracy: 0.8550 - val_loss: 1.0255 - val_accuracy: 0.7468\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.97248\n",
            "Epoch 8/200\n",
            "2198/2198 [==============================] - 652s 297ms/step - loss: 0.4428 - accuracy: 0.8679 - val_loss: 0.9818 - val_accuracy: 0.7724\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.97248\n",
            "Epoch 9/200\n",
            "2198/2198 [==============================] - 657s 299ms/step - loss: 0.3584 - accuracy: 0.8923 - val_loss: 0.9565 - val_accuracy: 0.8013\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.97248 to 0.95653, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER4_epoch_009_val_0.957_accuracy_0.801.h5\n",
            "Epoch 10/200\n",
            "2198/2198 [==============================] - 656s 299ms/step - loss: 0.3196 - accuracy: 0.9032 - val_loss: 1.0028 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.95653\n",
            "Epoch 11/200\n",
            "2198/2198 [==============================] - 655s 298ms/step - loss: 0.2953 - accuracy: 0.9095 - val_loss: 0.9893 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.95653\n",
            "Epoch 12/200\n",
            "2198/2198 [==============================] - 639s 291ms/step - loss: 0.2439 - accuracy: 0.9245 - val_loss: 1.0047 - val_accuracy: 0.7981\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.95653\n",
            "Epoch 13/200\n",
            "2198/2198 [==============================] - 641s 292ms/step - loss: 0.2131 - accuracy: 0.9344 - val_loss: 1.0412 - val_accuracy: 0.8013\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.95653\n",
            "Epoch 14/200\n",
            "2198/2198 [==============================] - 638s 290ms/step - loss: 0.1975 - accuracy: 0.9395 - val_loss: 1.0379 - val_accuracy: 0.7885\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.95653\n",
            "... Validating on fold 10 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 468.29it/s]\n",
            "  1%|▏         | 983/70325 [00:00<00:07, 9822.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(70325, 600, 6) (70325,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70325/70325 [00:09<00:00, 7396.16it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 9063.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2198/2198 [==============================] - 667s 292ms/step - loss: 2.1790 - accuracy: 0.5111 - val_loss: 1.5577 - val_accuracy: 0.6186\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.55771, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER4_epoch_001_val_1.558_accuracy_0.619.h5\n",
            "Epoch 2/200\n",
            "2198/2198 [==============================] - 640s 291ms/step - loss: 1.4176 - accuracy: 0.6110 - val_loss: 1.1083 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.55771 to 1.10831, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER4_epoch_002_val_1.108_accuracy_0.718.h5\n",
            "Epoch 3/200\n",
            "2198/2198 [==============================] - 626s 285ms/step - loss: 1.0043 - accuracy: 0.7107 - val_loss: 1.0033 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.10831 to 1.00333, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER4_epoch_003_val_1.003_accuracy_0.724.h5\n",
            "Epoch 4/200\n",
            "2198/2198 [==============================] - 619s 282ms/step - loss: 0.8122 - accuracy: 0.7585 - val_loss: 0.9676 - val_accuracy: 0.7436\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.00333 to 0.96756, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER4_epoch_004_val_0.968_accuracy_0.744.h5\n",
            "Epoch 5/200\n",
            "2198/2198 [==============================] - 619s 282ms/step - loss: 0.6428 - accuracy: 0.8089 - val_loss: 0.9646 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.96756 to 0.96457, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER4_epoch_005_val_0.965_accuracy_0.740.h5\n",
            "Epoch 6/200\n",
            "2198/2198 [==============================] - 626s 285ms/step - loss: 0.5785 - accuracy: 0.8291 - val_loss: 0.8977 - val_accuracy: 0.7885\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.96457 to 0.89774, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER4_epoch_006_val_0.898_accuracy_0.788.h5\n",
            "Epoch 7/200\n",
            "2198/2198 [==============================] - 625s 284ms/step - loss: 0.5008 - accuracy: 0.8507 - val_loss: 0.9307 - val_accuracy: 0.7564\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.89774\n",
            "Epoch 8/200\n",
            "2198/2198 [==============================] - 640s 291ms/step - loss: 0.4181 - accuracy: 0.8752 - val_loss: 0.8974 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.89774 to 0.89736, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER4_epoch_008_val_0.897_accuracy_0.766.h5\n",
            "Epoch 9/200\n",
            "2198/2198 [==============================] - 655s 298ms/step - loss: 0.3668 - accuracy: 0.8892 - val_loss: 0.9295 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.89736\n",
            "Epoch 10/200\n",
            "2002/2198 [==========================>...] - ETA: 58s - loss: 0.3216 - accuracy: 0.9014"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eVlKoJT3sKT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HqbXIafdXKb"
      },
      "source": [
        "## Make prediction\n",
        "model1 = load_model('drive/MyDrive/movement_detection/kfold1/testNoise_epoch_004_val_0.905_accuracy_0.757.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model2 = load_model('drive/MyDrive/movement_detection/kfold2/testNoise_epoch_002_val_1.010_accuracy_0.725.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model3 = load_model('drive/MyDrive/movement_detection/kfold3/testNoise_epoch_004_val_0.957_accuracy_0.751.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})  \n",
        "model4 = load_model('drive/MyDrive/movement_detection/kfold4/testNoise_epoch_002_val_0.994_accuracy_0.709.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model5 = load_model('drive/MyDrive/movement_detection/kfold5/testNoise_epoch_004_val_0.966_accuracy_0.748.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model6 = load_model('drive/MyDrive/movement_detection/kfold6/testNoise_epoch_004_val_0.854_accuracy_0.772.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model7 = load_model('drive/MyDrive/movement_detection/kfold7/testNoise_epoch_003_val_1.004_accuracy_0.731.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model8 = load_model('drive/MyDrive/movement_detection/kfold8/testNoise_epoch_004_val_0.859_accuracy_0.763.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model9 = load_model('drive/MyDrive/movement_detection/kfold9/testNoise_epoch_002_val_1.107_accuracy_0.734.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model10 = load_model('drive/MyDrive/movement_detection/kfold10/testNoise_epoch_004_val_0.966_accuracy_0.763.h5',\n",
        "                     custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IIblObVdhHv"
      },
      "source": [
        "X_test = tf.reshape(np.array(test_features.iloc[:,2:]),[-1, 600, 6])\n",
        "X_test = np.asarray(X_test)\n",
        "\n",
        "##### feature engineering for test dataset ##### \n",
        "X_test_fourier_real = [] \n",
        "X_test_fourier_imag = [] \n",
        "for i in tqdm(range(X_test.shape[0]), position = 0, leave = True):\n",
        "    real_part = np.fft.fft(X_test[i]).real \n",
        "    imag_part = np.fft.fft(X_test[i]).imag \n",
        "    X_test_fourier_real.append(real_part) \n",
        "    X_test_fourier_imag.append(imag_part)\n",
        "    \n",
        "X_test_fourier_real = np.asarray(X_test_fourier_real) \n",
        "X_test_fourier_imag = np.asarray(X_test_fourier_imag)\n",
        "X_test = np.concatenate([X_test, X_test_fourier_real, X_test_fourier_imag], axis = 2)  \n",
        "\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEPpB3Nd-oLP"
      },
      "source": [
        "p1 = model1.predict(X_test) \n",
        "p2 = model2.predict(X_test)\n",
        "p3 = model3.predict(X_test) \n",
        "p4 = model4.predict(X_test) \n",
        "p5 = model5.predict(X_test) \n",
        "p6 = model6.predict(X_test) \n",
        "p7 = model7.predict(X_test) \n",
        "p8 = model8.predict(X_test)\n",
        "p9 = model9.predict(X_test)\n",
        "p10 = model10.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFv6Id1N-rYY"
      },
      "source": [
        "p_avg = (p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + p10)/10.0\n",
        "\n",
        "sample_submission.iloc[:,1:] = p_avg\n",
        "\n",
        "sample_submission.to_csv(\"drive/MyDrive/movement_detection/TRANSFORMER4.csv\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}