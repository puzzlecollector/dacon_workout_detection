{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRANSFORMER 5.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEQ7s-cBcjOT",
        "outputId": "39d37c65-694d-408d-9efe-17c1ad969df4"
      },
      "source": [
        "pip install tsaug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tsaug in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from tsaug) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from tsaug) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g8Gzwfjcml3"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os, datetime \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *  \n",
        "from tensorflow.keras.callbacks import *\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold \n",
        "from tqdm import tqdm\n",
        "import random \n",
        "import time\n",
        "import pywt\n",
        "import tsaug\n",
        "from tsaug import TimeWarp, Crop, Quantize, Drift, Reverse "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8uWQbJccz9F"
      },
      "source": [
        "## Load data \n",
        "train_features = pd.read_csv('drive/MyDrive/movement_detection/train_features.csv')\n",
        "train_labels = pd.read_csv('drive/MyDrive/movement_detection/train_labels.csv')\n",
        "test_features = pd.read_csv('drive/MyDrive/movement_detection/test_features.csv')\n",
        "sample_submission = pd.read_csv('drive/MyDrive/movement_detection/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9zIZNwuc2Op",
        "outputId": "58e8dc74-91cf-4675-de8a-9738472b8933"
      },
      "source": [
        "X = tf.reshape(np.array(train_features.iloc[:,2:]),[-1, 600, 6])\n",
        "X = np.asarray(X) \n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3125, 600, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX0LMS8bc3lt",
        "outputId": "13536489-684f-482c-d8eb-9fc288dc6a1e"
      },
      "source": [
        "y = train_labels['label'].values\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3125,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0CDDDsBc4wt"
      },
      "source": [
        "batch_size = 32\n",
        "seq_len = 600 # temporary \n",
        "d_k = 256 \n",
        "d_v = 256\n",
        "n_heads = 12 \n",
        "ff_dim = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1x4udS3c6ox"
      },
      "source": [
        "class SingleAttention(Layer):\n",
        "    def __init__(self, d_k, d_v):\n",
        "        super(SingleAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.query = Dense(self.d_k, \n",
        "                       input_shape=input_shape, \n",
        "                       kernel_initializer='glorot_uniform', \n",
        "                       bias_initializer='glorot_uniform')\n",
        "    \n",
        "        self.key = Dense(self.d_k, \n",
        "                     input_shape=input_shape, \n",
        "                     kernel_initializer='glorot_uniform', \n",
        "                     bias_initializer='glorot_uniform')\n",
        "    \n",
        "        self.value = Dense(self.d_v, \n",
        "                       input_shape=input_shape, \n",
        "                       kernel_initializer='glorot_uniform', \n",
        "                       bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "        q = self.query(inputs[0])\n",
        "        k = self.key(inputs[1])\n",
        "\n",
        "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
        "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
        "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
        "    \n",
        "        v = self.value(inputs[2])\n",
        "        attn_out = tf.matmul(attn_weights, v)\n",
        "        return attn_out    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9_RBJRhc8QB"
      },
      "source": [
        "class MultiAttention(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads):\n",
        "        super(MultiAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.attn_heads = list()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        for n in range(self.n_heads):\n",
        "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
        "    \n",
        "        self.linear = Dense(input_shape[0][-1], \n",
        "                        input_shape=input_shape, \n",
        "                        kernel_initializer='glorot_uniform', \n",
        "                        bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
        "        concat_attn = tf.concat(attn, axis=-1)\n",
        "        multi_linear = self.linear(concat_attn)\n",
        "        return multi_linear   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijzuNPNDc9pt"
      },
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.attn_heads = []\n",
        "        self.dropout_rate = dropout \n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
        "        self.attn_dropout = Dropout(self.dropout_rate)\n",
        "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
        "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
        "        self.ff_dropout = Dropout(self.dropout_rate)\n",
        "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
        "  \n",
        "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq) \n",
        "        attn_layer = self.attn_multi(inputs) \n",
        "        attn_layer = self.attn_dropout(attn_layer)\n",
        "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
        "        ff_layer = self.ff_conv1D_1(attn_layer)  \n",
        "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
        "        ff_layer = self.ff_dropout(ff_layer)\n",
        "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
        "        return ff_layer \n",
        "\n",
        "    def get_config(self): # Needed for saving and loading model with custom layer\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'d_k': self.d_k,\n",
        "                   'd_v': self.d_v,\n",
        "                   'n_heads': self.n_heads,\n",
        "                   'ff_dim': self.ff_dim,\n",
        "                   'attn_heads': self.attn_heads,\n",
        "                   'dropout_rate': self.dropout_rate})\n",
        "        return config\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uarXHQvMc_48"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3gD63TtdB-P"
      },
      "source": [
        "def build_model(seq_len, features): \n",
        "  inputs = Input(shape=(seq_len,features))   \n",
        "  bn = BatchNormalization()(inputs)    \n",
        "\n",
        "  conv = Conv1D(256, 5, activation = 'relu', padding = 'same')(bn) \n",
        "  bn = BatchNormalization()(conv) \n",
        "  maxpool = MaxPooling1D()(bn) \n",
        "  conv = Conv1D(256, 5, activation = 'relu', padding = 'same')(maxpool) \n",
        "  bn = BatchNormalization()(conv) \n",
        "  features = MaxPooling1D()(bn) \n",
        "\n",
        "  pos_encoding = positional_encoding(seq_len, d_k)    \n",
        "  features *= tf.math.sqrt(tf.cast(d_k, tf.float32)) # scale  \n",
        "  features += pos_encoding[:, :features.shape[1], :] # add positional encoding \n",
        "\n",
        "  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "\n",
        "  x = attn_layer1((features, features, features))   \n",
        "  x = attn_layer2((x, x, x)) \n",
        "  x = attn_layer3((x, x, x)) \n",
        "\n",
        "  bi_gru = Bidirectional(GRU(128, return_sequences = False))(x) \n",
        "  dropout = Dropout(0.25)(bi_gru) \n",
        "  dense = Dense(128, activation = 'relu')(dropout) \n",
        "  bn = BatchNormalization()(dense) \n",
        "  outputs = Dense(61, activation='softmax')(bn) \n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf_2WkrEdEna",
        "outputId": "881527a6-34f7-463b-9b0f-afd1d432aadc"
      },
      "source": [
        "model = build_model(600, 18)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 600, 18)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 600, 18)      72          input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 600, 256)     23296       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 600, 256)     1024        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 300, 256)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 300, 256)     327936      max_pooling1d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 300, 256)     1024        conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 150, 256)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_3 (TFOpLambda) (None, 150, 256)     0           max_pooling1d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 150, 256)     0           tf.math.multiply_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_9 (Transfor (None, 150, 256)     3419136     tf.__operators__.add_3[0][0]     \n",
            "                                                                 tf.__operators__.add_3[0][0]     \n",
            "                                                                 tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_10 (Transfo (None, 150, 256)     3419136     transformer_encoder_9[0][0]      \n",
            "                                                                 transformer_encoder_9[0][0]      \n",
            "                                                                 transformer_encoder_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_11 (Transfo (None, 150, 256)     3419136     transformer_encoder_10[0][0]     \n",
            "                                                                 transformer_encoder_10[0][0]     \n",
            "                                                                 transformer_encoder_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 256)          296448      transformer_encoder_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 256)          0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 128)          32896       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128)          512         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 61)           7869        batch_normalization_15[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 10,948,485\n",
            "Trainable params: 10,947,169\n",
            "Non-trainable params: 1,316\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE4uhiyOdJPw",
        "outputId": "df9db533-e0a3-4a0b-c30f-867a27d7dd7b"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits = 10, random_state = 960418, shuffle = True)\n",
        "for idx,(train_idx, val_idx) in enumerate(kfold.split(X,y)):   \n",
        "    print(\"... Validating on fold {} ...\".format(idx+1))   \n",
        "    if idx < 8: \n",
        "      continue \n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx] \n",
        "    \n",
        "    ##### augment data #####\n",
        "    print(\"... Augmenting Data ...\")\n",
        "    X_augmented = [] \n",
        "    y_augmented = [] \n",
        "\n",
        "    for i in tqdm(range(X_train.shape[0]), position = 0, leave = True): \n",
        "        for j in range(10): # add random shift \n",
        "            shifted = np.roll(X_train[i], int(random.random() * 600)) \n",
        "            X_augmented.append(shifted) \n",
        "            y_augmented.append(y_train[i]) \n",
        "        for j in range(10): # add noise \n",
        "            noised = np.random.normal(0, 1, X_train[i].shape) + X_train[i] \n",
        "            X_augmented.append(noised) \n",
        "            y_augmented.append(y_train[i])   \n",
        "    \n",
        "\n",
        "    X_cropped = Crop(random.randint(300, 580), resize = 600).augment(X_train) \n",
        "    X_warped = TimeWarp(random.randint(3,20)).augment(X_train)  \n",
        "    #X_reversed = Reverse().augment(X_train) \n",
        "    X_quantized = Quantize(random.randint(10,100)).augment(X_train) \n",
        "    x_drift = Drift(max_drift=(0.1,0.5)).augment(X_train)\n",
        "    x_drift2 = Drift(max_drift=(0.1,0.5)).augment(X_train)\n",
        "\n",
        "    X_augmented = np.asarray(X_augmented) \n",
        "    y_augmented = np.asarray(y_augmented)    \n",
        "\n",
        "    X_train = np.concatenate([X_train, X_augmented, X_cropped, X_warped, x_drift, x_drift2, X_quantized]) \n",
        "    y_train = np.concatenate([y_train, y_augmented, y_train, y_train, y_train, y_train, y_train])  \n",
        "\n",
        "    print(\"Train shapes\")\n",
        "    print(X_train.shape, y_train.shape)  \n",
        "\n",
        "    ###### feature engineering data ##### \n",
        "    print(\"... DFFT Feature Engineering ...\")\n",
        "    X_fourier_real = [] \n",
        "    X_fourier_imag = [] \n",
        "    for i in tqdm(range(X_train.shape[0]), position = 0, leave = True):  \n",
        "        real_part = np.fft.fft(X_train[i]).real \n",
        "        imag_part = np.fft.fft(X_train[i]).imag \n",
        "        X_fourier_real.append(real_part)\n",
        "        X_fourier_imag.append(imag_part) \n",
        "    \n",
        "    X_fourier_real = np.asarray(X_fourier_real)  \n",
        "    X_fourier_imag = np.asarray(X_fourier_imag)\n",
        "    \n",
        "    \n",
        "    X_val_fourier_real = [] \n",
        "    X_val_fourier_imag = [] \n",
        "    for i in tqdm(range(X_val.shape[0]), position = 0, leave = True):\n",
        "        real_part = np.fft.fft(X_val[i]).real \n",
        "        imag_part = np.fft.fft(X_val[i]).imag \n",
        "        X_val_fourier_real.append(real_part) \n",
        "        X_val_fourier_imag.append(imag_part)\n",
        "    \n",
        "    X_val_fourier_real = np.asarray(X_val_fourier_real) \n",
        "    X_val_fourier_imag = np.asarray(X_val_fourier_imag)\n",
        "    \n",
        "    X_train = np.concatenate([X_train, X_fourier_real, X_fourier_imag], axis = 2)  \n",
        "    X_val = np.concatenate([X_val, X_val_fourier_real, X_val_fourier_imag], axis = 2)\n",
        "\n",
        "    ##### train model #####  \n",
        "    print(\"... Building Model ...\")\n",
        "    # we have 18 features after feature engineering \n",
        "    model = build_model(600, 18) \n",
        "    print(\"... Training ...\") \n",
        "    model_path = 'drive/MyDrive/movement_detection/kfold' + str(idx+1) + '/TRANSFORMER5_epoch_{epoch:03d}_val_{val_loss:.3f}_accuracy_{val_accuracy:.3f}.h5'\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 1, verbose = 1, factor = 0.8)\n",
        "    checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
        "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5) \n",
        "\n",
        "    model.fit(X_train,\n",
        "              y_train,\n",
        "              epochs = 200,\n",
        "              batch_size = 32, # hyperparameter  \n",
        "              validation_data = (X_val, y_val), \n",
        "              callbacks = [learning_rate_reduction, checkpoint, early_stopping])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 51/2813 [00:00<00:05, 501.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Validating on fold 1 ...\n",
            "... Validating on fold 2 ...\n",
            "... Validating on fold 3 ...\n",
            "... Validating on fold 4 ...\n",
            "... Validating on fold 5 ...\n",
            "... Validating on fold 6 ...\n",
            "... Validating on fold 7 ...\n",
            "... Validating on fold 8 ...\n",
            "... Validating on fold 9 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 433.76it/s]\n",
            "  1%|          | 830/73138 [00:00<00:08, 8295.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73138, 600, 6) (73138,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73138/73138 [00:10<00:00, 6673.34it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 8536.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2286/2286 [==============================] - 892s 376ms/step - loss: 2.2846 - accuracy: 0.5041 - val_loss: 1.6092 - val_accuracy: 0.5865\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.60920, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_001_val_1.609_accuracy_0.587.h5\n",
            "Epoch 2/200\n",
            "2286/2286 [==============================] - 845s 370ms/step - loss: 1.3685 - accuracy: 0.6261 - val_loss: 1.2607 - val_accuracy: 0.6699\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.60920 to 1.26073, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_002_val_1.261_accuracy_0.670.h5\n",
            "Epoch 3/200\n",
            "2286/2286 [==============================] - 839s 367ms/step - loss: 1.0268 - accuracy: 0.7092 - val_loss: 1.2053 - val_accuracy: 0.6955\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.26073 to 1.20525, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_003_val_1.205_accuracy_0.696.h5\n",
            "Epoch 4/200\n",
            "2286/2286 [==============================] - 839s 367ms/step - loss: 0.8269 - accuracy: 0.7588 - val_loss: 0.9735 - val_accuracy: 0.7596\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.20525 to 0.97354, saving model to drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_004_val_0.974_accuracy_0.760.h5\n",
            "Epoch 5/200\n",
            "2286/2286 [==============================] - 835s 365ms/step - loss: 0.6999 - accuracy: 0.7946 - val_loss: 1.1070 - val_accuracy: 0.7468\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.97354\n",
            "Epoch 6/200\n",
            "2286/2286 [==============================] - 832s 364ms/step - loss: 0.5464 - accuracy: 0.8365 - val_loss: 1.0827 - val_accuracy: 0.7756\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.97354\n",
            "Epoch 7/200\n",
            "2286/2286 [==============================] - 831s 364ms/step - loss: 0.4428 - accuracy: 0.8670 - val_loss: 1.0061 - val_accuracy: 0.7821\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.97354\n",
            "Epoch 8/200\n",
            "2286/2286 [==============================] - 830s 363ms/step - loss: 0.3765 - accuracy: 0.8839 - val_loss: 1.0667 - val_accuracy: 0.7853\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.97354\n",
            "Epoch 9/200\n",
            "2286/2286 [==============================] - 831s 363ms/step - loss: 0.3166 - accuracy: 0.9034 - val_loss: 0.9948 - val_accuracy: 0.7885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 52/2813 [00:00<00:05, 511.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.97354\n",
            "... Validating on fold 10 ...\n",
            "... Augmenting Data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2813/2813 [00:06<00:00, 462.49it/s]\n",
            "  1%|          | 807/73138 [00:00<00:08, 8063.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train shapes\n",
            "(73138, 600, 6) (73138,)\n",
            "... DFFT Feature Engineering ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73138/73138 [00:10<00:00, 7007.15it/s]\n",
            "100%|██████████| 312/312 [00:00<00:00, 8422.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Building Model ...\n",
            "... Training ...\n",
            "Epoch 1/200\n",
            "2286/2286 [==============================] - 871s 369ms/step - loss: 2.3299 - accuracy: 0.4962 - val_loss: 1.5288 - val_accuracy: 0.6026\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.52885, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER5_epoch_001_val_1.529_accuracy_0.603.h5\n",
            "Epoch 2/200\n",
            "2286/2286 [==============================] - 841s 368ms/step - loss: 1.3870 - accuracy: 0.6249 - val_loss: 1.1089 - val_accuracy: 0.6987\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.52885 to 1.10888, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER5_epoch_002_val_1.109_accuracy_0.699.h5\n",
            "Epoch 3/200\n",
            "2286/2286 [==============================] - 843s 369ms/step - loss: 1.0386 - accuracy: 0.7044 - val_loss: 0.9398 - val_accuracy: 0.7404\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.10888 to 0.93981, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER5_epoch_003_val_0.940_accuracy_0.740.h5\n",
            "Epoch 4/200\n",
            "2286/2286 [==============================] - 844s 369ms/step - loss: 0.8601 - accuracy: 0.7515 - val_loss: 0.9742 - val_accuracy: 0.7532\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.93981\n",
            "Epoch 5/200\n",
            "2286/2286 [==============================] - 842s 368ms/step - loss: 0.7139 - accuracy: 0.7924 - val_loss: 0.9320 - val_accuracy: 0.7564\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.93981 to 0.93198, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER5_epoch_005_val_0.932_accuracy_0.756.h5\n",
            "Epoch 6/200\n",
            "2286/2286 [==============================] - 843s 369ms/step - loss: 0.6091 - accuracy: 0.8214 - val_loss: 0.9350 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.93198\n",
            "Epoch 7/200\n",
            "2286/2286 [==============================] - 841s 368ms/step - loss: 0.5087 - accuracy: 0.8502 - val_loss: 0.9206 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.93198 to 0.92057, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER5_epoch_007_val_0.921_accuracy_0.750.h5\n",
            "Epoch 8/200\n",
            "2286/2286 [==============================] - 841s 368ms/step - loss: 0.4741 - accuracy: 0.8594 - val_loss: 0.8796 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.92057 to 0.87960, saving model to drive/MyDrive/movement_detection/kfold10/TRANSFORMER5_epoch_008_val_0.880_accuracy_0.769.h5\n",
            "Epoch 9/200\n",
            "2286/2286 [==============================] - 841s 368ms/step - loss: 0.4179 - accuracy: 0.8732 - val_loss: 0.9009 - val_accuracy: 0.7436\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.87960\n",
            "Epoch 10/200\n",
            "2286/2286 [==============================] - 839s 367ms/step - loss: 0.3586 - accuracy: 0.8917 - val_loss: 0.9230 - val_accuracy: 0.7756\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.87960\n",
            "Epoch 11/200\n",
            "2286/2286 [==============================] - 839s 367ms/step - loss: 0.3205 - accuracy: 0.9014 - val_loss: 0.9623 - val_accuracy: 0.7628\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.87960\n",
            "Epoch 12/200\n",
            "2286/2286 [==============================] - 838s 367ms/step - loss: 0.2905 - accuracy: 0.9096 - val_loss: 0.9413 - val_accuracy: 0.7756\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.87960\n",
            "Epoch 13/200\n",
            "2286/2286 [==============================] - 838s 367ms/step - loss: 0.2476 - accuracy: 0.9227 - val_loss: 0.9135 - val_accuracy: 0.7821\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.87960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytI7Nm2Qd2hJ"
      },
      "source": [
        "### Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnfhr3gSdObP"
      },
      "source": [
        "## Make prediction\n",
        "model1 = load_model('drive/MyDrive/movement_detection/kfold1/TRANSFORMER5_epoch_006_val_0.845_accuracy_0.780.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model2 = load_model('drive/MyDrive/movement_detection/kfold2/TRANSFORMER5_epoch_006_val_1.022_accuracy_0.773.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model3 = load_model('drive/MyDrive/movement_detection/kfold3/TRANSFORMER5_epoch_009_val_0.875_accuracy_0.751.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})  \n",
        "model4 = load_model('drive/MyDrive/movement_detection/kfold4/TRANSFORMER5_epoch_004_val_0.868_accuracy_0.770.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model5 = load_model('drive/MyDrive/movement_detection/kfold5/TRANSFORMER5_epoch_008_val_0.877_accuracy_0.751.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model6 = load_model('drive/MyDrive/movement_detection/kfold6/TRANSFORMER5_epoch_008_val_0.841_accuracy_0.776.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model7 = load_model('drive/MyDrive/movement_detection/kfold7/TRANSFORMER5_epoch_006_val_0.945_accuracy_0.747.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model8 = load_model('drive/MyDrive/movement_detection/kfold8/TRANSFORMER5_epoch_007_val_0.807_accuracy_0.795.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n",
        "model9 = load_model('drive/MyDrive/movement_detection/kfold9/TRANSFORMER5_epoch_004_val_0.974_accuracy_0.760.h5',\n",
        "                    custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder}) \n",
        "model10 = load_model('drive/MyDrive/movement_detection/kfold10/TRANSFORMER5_epoch_008_val_0.880_accuracy_0.769.h5',\n",
        "                     custom_objects={'SingleAttention': SingleAttention,\n",
        "                                    'MultiAttention': MultiAttention,\n",
        "                                    'TransformerEncoder': TransformerEncoder})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt3a73gEd6sk",
        "outputId": "df646f25-66c0-4b22-b952-f8b733b73b74"
      },
      "source": [
        "X_test = tf.reshape(np.array(test_features.iloc[:,2:]),[-1, 600, 6])\n",
        "X_test = np.asarray(X_test)\n",
        "\n",
        "##### feature engineering for test dataset ##### \n",
        "X_test_fourier_real = [] \n",
        "X_test_fourier_imag = [] \n",
        "for i in tqdm(range(X_test.shape[0]), position = 0, leave = True):\n",
        "    real_part = np.fft.fft(X_test[i]).real \n",
        "    imag_part = np.fft.fft(X_test[i]).imag \n",
        "    X_test_fourier_real.append(real_part) \n",
        "    X_test_fourier_imag.append(imag_part)\n",
        "    \n",
        "X_test_fourier_real = np.asarray(X_test_fourier_real) \n",
        "X_test_fourier_imag = np.asarray(X_test_fourier_imag)\n",
        "X_test = np.concatenate([X_test, X_test_fourier_real, X_test_fourier_imag], axis = 2)  \n",
        "\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:00<00:00, 7931.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(782, 600, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSno75H_d8MS"
      },
      "source": [
        "p1 = model1.predict(X_test) \n",
        "p2 = model2.predict(X_test)\n",
        "p3 = model3.predict(X_test) \n",
        "p4 = model4.predict(X_test) \n",
        "p5 = model5.predict(X_test) \n",
        "p6 = model6.predict(X_test) \n",
        "p7 = model7.predict(X_test) \n",
        "p8 = model8.predict(X_test)\n",
        "p9 = model9.predict(X_test)\n",
        "p10 = model10.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uYap61Xd9xG"
      },
      "source": [
        "p_avg = (p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + p10)/10.0\n",
        "\n",
        "sample_submission.iloc[:,1:] = p_avg\n",
        "\n",
        "sample_submission.to_csv(\"drive/MyDrive/movement_detection/TRANSFORMER5.csv\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "EjhpIGz_3gX_",
        "outputId": "25f05ae8-a0c3-4401-bcb1-ccde752591fe"
      },
      "source": [
        "sample_submission.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3125</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.007436</td>\n",
              "      <td>1.401601e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>7.949520e-06</td>\n",
              "      <td>2.362740e-07</td>\n",
              "      <td>3.561443e-01</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1.416515e-01</td>\n",
              "      <td>0.008005</td>\n",
              "      <td>0.025651</td>\n",
              "      <td>1.930055e-04</td>\n",
              "      <td>1.143995e-01</td>\n",
              "      <td>1.693907e-03</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>4.895598e-05</td>\n",
              "      <td>2.867183e-06</td>\n",
              "      <td>3.571093e-07</td>\n",
              "      <td>1.088238e-07</td>\n",
              "      <td>4.754262e-08</td>\n",
              "      <td>2.309630e-06</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.031641</td>\n",
              "      <td>4.054242e-08</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>1.126721e-04</td>\n",
              "      <td>1.974843e-05</td>\n",
              "      <td>4.044059e-05</td>\n",
              "      <td>3.177684e-03</td>\n",
              "      <td>3.825420e-03</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>0.002630</td>\n",
              "      <td>2.586676e-07</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>1.006411e-01</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>1.796447e-05</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>1.628113e-05</td>\n",
              "      <td>0.003735</td>\n",
              "      <td>1.051764e-03</td>\n",
              "      <td>1.234113e-03</td>\n",
              "      <td>1.189067e-01</td>\n",
              "      <td>3.147759e-07</td>\n",
              "      <td>1.040777e-03</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>2.894796e-04</td>\n",
              "      <td>1.840739e-04</td>\n",
              "      <td>1.389596e-05</td>\n",
              "      <td>3.010781e-04</td>\n",
              "      <td>1.617996e-07</td>\n",
              "      <td>4.162893e-07</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>7.439244e-02</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3126</td>\n",
              "      <td>0.002013</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>2.160408e-06</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>4.974107e-05</td>\n",
              "      <td>2.738084e-05</td>\n",
              "      <td>6.918542e-05</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.433570e-04</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>1.553026e-06</td>\n",
              "      <td>9.864052e-05</td>\n",
              "      <td>2.755388e-05</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>4.670482e-06</td>\n",
              "      <td>1.436771e-07</td>\n",
              "      <td>6.798722e-07</td>\n",
              "      <td>3.071994e-08</td>\n",
              "      <td>9.049166e-07</td>\n",
              "      <td>2.917264e-04</td>\n",
              "      <td>0.002291</td>\n",
              "      <td>0.004111</td>\n",
              "      <td>0.000563</td>\n",
              "      <td>6.718709e-07</td>\n",
              "      <td>0.980554</td>\n",
              "      <td>5.075434e-04</td>\n",
              "      <td>1.560579e-07</td>\n",
              "      <td>5.843457e-06</td>\n",
              "      <td>3.051195e-05</td>\n",
              "      <td>1.235446e-05</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000745</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>1.725901e-03</td>\n",
              "      <td>0.003418</td>\n",
              "      <td>2.393393e-04</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>2.162309e-07</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>2.694874e-05</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>6.336554e-05</td>\n",
              "      <td>2.263626e-05</td>\n",
              "      <td>1.304799e-05</td>\n",
              "      <td>3.845529e-08</td>\n",
              "      <td>5.880388e-04</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>8.150922e-06</td>\n",
              "      <td>3.796707e-07</td>\n",
              "      <td>1.135399e-06</td>\n",
              "      <td>2.403522e-04</td>\n",
              "      <td>1.085352e-05</td>\n",
              "      <td>4.543114e-04</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>8.178251e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3127</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>0.004283</td>\n",
              "      <td>7.686950e-07</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>7.585693e-04</td>\n",
              "      <td>1.020399e-04</td>\n",
              "      <td>2.248980e-01</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>0.000886</td>\n",
              "      <td>1.990268e-01</td>\n",
              "      <td>0.030124</td>\n",
              "      <td>0.002260</td>\n",
              "      <td>2.494193e-03</td>\n",
              "      <td>1.743367e-04</td>\n",
              "      <td>9.256903e-02</td>\n",
              "      <td>0.001801</td>\n",
              "      <td>5.077222e-06</td>\n",
              "      <td>1.873203e-05</td>\n",
              "      <td>1.260076e-06</td>\n",
              "      <td>3.703055e-06</td>\n",
              "      <td>1.156660e-06</td>\n",
              "      <td>2.719016e-05</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.004432</td>\n",
              "      <td>2.981573e-05</td>\n",
              "      <td>0.063663</td>\n",
              "      <td>1.706253e-05</td>\n",
              "      <td>7.880445e-04</td>\n",
              "      <td>2.744436e-03</td>\n",
              "      <td>1.354744e-03</td>\n",
              "      <td>2.062365e-02</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.002615</td>\n",
              "      <td>0.005653</td>\n",
              "      <td>1.850783e-06</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>5.905280e-04</td>\n",
              "      <td>0.038311</td>\n",
              "      <td>5.459167e-03</td>\n",
              "      <td>0.002360</td>\n",
              "      <td>2.116150e-04</td>\n",
              "      <td>0.023730</td>\n",
              "      <td>5.522224e-02</td>\n",
              "      <td>6.809728e-03</td>\n",
              "      <td>5.021786e-02</td>\n",
              "      <td>1.118109e-06</td>\n",
              "      <td>2.292797e-03</td>\n",
              "      <td>0.063733</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>0.004666</td>\n",
              "      <td>2.228564e-04</td>\n",
              "      <td>1.687676e-03</td>\n",
              "      <td>4.536890e-06</td>\n",
              "      <td>3.865144e-04</td>\n",
              "      <td>5.678026e-07</td>\n",
              "      <td>6.545043e-06</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>4.105891e-03</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.073874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3128</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>1.112199e-05</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>2.816918e-07</td>\n",
              "      <td>2.645404e-06</td>\n",
              "      <td>4.663108e-05</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>2.233491e-04</td>\n",
              "      <td>0.001026</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>7.738176e-06</td>\n",
              "      <td>5.912469e-05</td>\n",
              "      <td>4.378840e-06</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>1.466839e-07</td>\n",
              "      <td>1.133459e-08</td>\n",
              "      <td>2.679222e-08</td>\n",
              "      <td>8.055929e-08</td>\n",
              "      <td>4.758979e-06</td>\n",
              "      <td>4.425796e-06</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>2.931396e-06</td>\n",
              "      <td>0.991817</td>\n",
              "      <td>1.804919e-05</td>\n",
              "      <td>1.019950e-04</td>\n",
              "      <td>1.666846e-04</td>\n",
              "      <td>2.921373e-05</td>\n",
              "      <td>3.602762e-06</td>\n",
              "      <td>0.000472</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.724515e-05</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>2.394157e-04</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>2.447706e-06</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>6.848777e-07</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>7.299525e-04</td>\n",
              "      <td>2.218455e-05</td>\n",
              "      <td>3.213164e-05</td>\n",
              "      <td>1.704685e-06</td>\n",
              "      <td>2.462052e-05</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.001991</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>3.060357e-04</td>\n",
              "      <td>1.957567e-05</td>\n",
              "      <td>2.997671e-06</td>\n",
              "      <td>1.392912e-05</td>\n",
              "      <td>1.543888e-06</td>\n",
              "      <td>2.578632e-06</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>4.669192e-05</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3129</td>\n",
              "      <td>0.003999</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>3.416995e-08</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>3.997518e-04</td>\n",
              "      <td>4.859513e-06</td>\n",
              "      <td>2.500400e-07</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>2.065563e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>3.646559e-07</td>\n",
              "      <td>9.788025e-07</td>\n",
              "      <td>1.176608e-07</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>4.291550e-07</td>\n",
              "      <td>1.745184e-05</td>\n",
              "      <td>9.207173e-05</td>\n",
              "      <td>5.085614e-07</td>\n",
              "      <td>1.284814e-06</td>\n",
              "      <td>2.702158e-07</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>3.311865e-04</td>\n",
              "      <td>0.991825</td>\n",
              "      <td>3.373535e-08</td>\n",
              "      <td>2.744117e-07</td>\n",
              "      <td>2.781438e-07</td>\n",
              "      <td>9.080115e-08</td>\n",
              "      <td>5.800208e-08</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>1.318418e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>3.133426e-07</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>3.489314e-08</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>3.685898e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>3.406946e-07</td>\n",
              "      <td>7.379851e-07</td>\n",
              "      <td>4.663409e-08</td>\n",
              "      <td>1.179113e-06</td>\n",
              "      <td>7.771314e-08</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>2.972443e-07</td>\n",
              "      <td>5.086524e-08</td>\n",
              "      <td>1.343769e-07</td>\n",
              "      <td>1.635109e-08</td>\n",
              "      <td>2.528747e-07</td>\n",
              "      <td>1.037568e-05</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>2.361140e-07</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id         0         1  ...            58        59        60\n",
              "0  3125  0.000002  0.007436  ...  7.439244e-02  0.000002  0.000007\n",
              "1  3126  0.002013  0.000121  ...  8.178251e-06  0.000003  0.000022\n",
              "2  3127  0.000474  0.004283  ...  4.105891e-03  0.000075  0.073874\n",
              "3  3128  0.000033  0.000086  ...  4.669192e-05  0.000004  0.000294\n",
              "4  3129  0.003999  0.000104  ...  2.361140e-07  0.002812  0.000007\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmGIE15Z3LPx"
      },
      "source": [
        "### Simple Average with TRANSFORMERS4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMplCwWb3JFq"
      },
      "source": [
        "df1 = pd.read_csv('drive/MyDrive/movement_detection/augmented_catboost_10_fold.csv') \n",
        "df2 = pd.read_csv('drive/MyDrive/movement_detection/fourier_transform_10_fold_transformer.csv') \n",
        "df3 = pd.read_csv('drive/MyDrive/movement_detection/TRANSFORMER4.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "WrKyvAtM3v2e",
        "outputId": "f7fb5eb7-65ce-4d28-bf4e-f03053b23340"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3125</td>\n",
              "      <td>9.081605e-07</td>\n",
              "      <td>0.001044</td>\n",
              "      <td>2.352382e-06</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>1.797859e-08</td>\n",
              "      <td>0.072556</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>4.761603e-06</td>\n",
              "      <td>3.857305e-01</td>\n",
              "      <td>0.021921</td>\n",
              "      <td>0.006374</td>\n",
              "      <td>6.028142e-05</td>\n",
              "      <td>0.066195</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>1.616942e-05</td>\n",
              "      <td>4.237456e-06</td>\n",
              "      <td>2.260830e-06</td>\n",
              "      <td>1.558267e-07</td>\n",
              "      <td>3.689771e-08</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>1.907352e-05</td>\n",
              "      <td>0.110615</td>\n",
              "      <td>2.239424e-08</td>\n",
              "      <td>0.000848</td>\n",
              "      <td>1.025441e-04</td>\n",
              "      <td>4.048818e-06</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>3.458976e-03</td>\n",
              "      <td>2.698886e-03</td>\n",
              "      <td>6.209315e-07</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.000904</td>\n",
              "      <td>1.049871e-07</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.108352</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>5.457492e-06</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001767</td>\n",
              "      <td>0.003120</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.014512</td>\n",
              "      <td>4.980681e-07</td>\n",
              "      <td>3.424833e-04</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>8.419883e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>8.074064e-05</td>\n",
              "      <td>1.001747e-04</td>\n",
              "      <td>4.935398e-06</td>\n",
              "      <td>2.453704e-04</td>\n",
              "      <td>4.431029e-07</td>\n",
              "      <td>2.518307e-07</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>1.976639e-01</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3126</td>\n",
              "      <td>1.272885e-04</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>1.788624e-06</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>7.212970e-05</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>6.695269e-07</td>\n",
              "      <td>5.139916e-07</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.475936e-07</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>1.077045e-05</td>\n",
              "      <td>1.259905e-07</td>\n",
              "      <td>4.231448e-07</td>\n",
              "      <td>3.059850e-07</td>\n",
              "      <td>1.068531e-05</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>0.003816</td>\n",
              "      <td>4.591198e-03</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>2.578334e-06</td>\n",
              "      <td>0.985056</td>\n",
              "      <td>1.816926e-04</td>\n",
              "      <td>2.780609e-07</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>5.632170e-07</td>\n",
              "      <td>2.397566e-07</td>\n",
              "      <td>2.083319e-05</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>1.159102e-04</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>5.864027e-08</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>6.183333e-07</td>\n",
              "      <td>1.342490e-04</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>1.121512e-04</td>\n",
              "      <td>0.000420</td>\n",
              "      <td>3.726168e-06</td>\n",
              "      <td>2.226584e-07</td>\n",
              "      <td>4.298704e-06</td>\n",
              "      <td>4.897235e-05</td>\n",
              "      <td>1.454090e-05</td>\n",
              "      <td>1.697289e-04</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>2.920221e-06</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3127</td>\n",
              "      <td>1.257084e-04</td>\n",
              "      <td>0.004882</td>\n",
              "      <td>7.105888e-07</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.001489</td>\n",
              "      <td>5.508380e-05</td>\n",
              "      <td>0.134924</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>6.286131e-04</td>\n",
              "      <td>1.399314e-01</td>\n",
              "      <td>0.023104</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>1.456636e-03</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.301508</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>7.752930e-07</td>\n",
              "      <td>3.696321e-06</td>\n",
              "      <td>1.014718e-06</td>\n",
              "      <td>2.490452e-06</td>\n",
              "      <td>6.346746e-07</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>9.914927e-07</td>\n",
              "      <td>0.004117</td>\n",
              "      <td>3.558511e-06</td>\n",
              "      <td>0.030898</td>\n",
              "      <td>2.081896e-05</td>\n",
              "      <td>9.579887e-05</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>5.905346e-04</td>\n",
              "      <td>4.458209e-04</td>\n",
              "      <td>6.425918e-04</td>\n",
              "      <td>0.000335</td>\n",
              "      <td>0.001312</td>\n",
              "      <td>1.639467e-07</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.043518</td>\n",
              "      <td>8.852709e-05</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.011777</td>\n",
              "      <td>0.119697</td>\n",
              "      <td>0.007739</td>\n",
              "      <td>0.114489</td>\n",
              "      <td>5.905679e-07</td>\n",
              "      <td>2.367747e-03</td>\n",
              "      <td>0.017213</td>\n",
              "      <td>1.015568e-04</td>\n",
              "      <td>0.003352</td>\n",
              "      <td>2.738126e-04</td>\n",
              "      <td>7.571237e-04</td>\n",
              "      <td>6.347996e-06</td>\n",
              "      <td>2.880204e-03</td>\n",
              "      <td>3.257040e-07</td>\n",
              "      <td>4.000462e-06</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>2.558826e-03</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.023308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3128</td>\n",
              "      <td>3.263539e-04</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>9.184938e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>2.449996e-05</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>5.277096e-05</td>\n",
              "      <td>4.618692e-05</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>3.383216e-06</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>8.755601e-08</td>\n",
              "      <td>4.082651e-07</td>\n",
              "      <td>2.547467e-07</td>\n",
              "      <td>9.758485e-07</td>\n",
              "      <td>2.447619e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>1.728163e-04</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>6.518309e-06</td>\n",
              "      <td>0.983585</td>\n",
              "      <td>5.980081e-06</td>\n",
              "      <td>7.869829e-05</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>2.847922e-06</td>\n",
              "      <td>1.257414e-06</td>\n",
              "      <td>1.926955e-03</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>2.106272e-05</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000774</td>\n",
              "      <td>1.214713e-05</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>3.546236e-06</td>\n",
              "      <td>2.436037e-06</td>\n",
              "      <td>0.000558</td>\n",
              "      <td>8.981172e-03</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>3.157568e-04</td>\n",
              "      <td>9.178193e-06</td>\n",
              "      <td>2.006680e-06</td>\n",
              "      <td>1.150025e-05</td>\n",
              "      <td>1.145742e-05</td>\n",
              "      <td>1.482017e-05</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>1.106385e-05</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3129</td>\n",
              "      <td>4.953754e-03</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>1.397904e-07</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>2.818148e-04</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>3.958289e-06</td>\n",
              "      <td>1.130473e-05</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>1.048256e-06</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>7.585890e-07</td>\n",
              "      <td>2.601285e-06</td>\n",
              "      <td>3.436940e-05</td>\n",
              "      <td>5.097426e-07</td>\n",
              "      <td>4.197907e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>6.185810e-05</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>6.072487e-04</td>\n",
              "      <td>0.985589</td>\n",
              "      <td>9.388564e-07</td>\n",
              "      <td>2.243995e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>8.613400e-06</td>\n",
              "      <td>2.143947e-05</td>\n",
              "      <td>2.255414e-04</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>9.610359e-07</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>1.386453e-06</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000325</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>3.821209e-05</td>\n",
              "      <td>5.072417e-07</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>6.687011e-04</td>\n",
              "      <td>0.000489</td>\n",
              "      <td>5.675259e-07</td>\n",
              "      <td>6.468594e-07</td>\n",
              "      <td>6.361000e-07</td>\n",
              "      <td>5.123571e-07</td>\n",
              "      <td>5.781205e-07</td>\n",
              "      <td>3.152082e-04</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>3.422962e-07</td>\n",
              "      <td>0.004843</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id             0         1  ...            58        59        60\n",
              "0  3125  9.081605e-07  0.001044  ...  1.976639e-01  0.000001  0.000016\n",
              "1  3126  1.272885e-04  0.000068  ...  2.920221e-06  0.000004  0.000286\n",
              "2  3127  1.257084e-04  0.004882  ...  2.558826e-03  0.000003  0.023308\n",
              "3  3128  3.263539e-04  0.000004  ...  1.106385e-05  0.000011  0.000415\n",
              "4  3129  4.953754e-03  0.000088  ...  3.422962e-07  0.004843  0.000033\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "lSwHJnA73w09",
        "outputId": "86460649-8935-4eda-cc4b-67fddf16a453"
      },
      "source": [
        "sample_submission.iloc[:,1:] = (df1.iloc[:,1:] + df2.iloc[:,1:] + df3.iloc[:,1:])/2.0 \n",
        "\n",
        "sample_submission.to_csv('drive/MyDrive/movement_detection/ensemble1.csv', index=False) \n",
        "\n",
        "sample_submission.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3125</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.200197</td>\n",
              "      <td>0.000859</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.270825</td>\n",
              "      <td>0.252255</td>\n",
              "      <td>0.051469</td>\n",
              "      <td>0.000565</td>\n",
              "      <td>0.155444</td>\n",
              "      <td>0.006312</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>0.161527</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.007678</td>\n",
              "      <td>0.000470</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>0.017436</td>\n",
              "      <td>0.004999</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.000582</td>\n",
              "      <td>0.002620</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.003424</td>\n",
              "      <td>0.092641</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.000309</td>\n",
              "      <td>0.029516</td>\n",
              "      <td>0.018736</td>\n",
              "      <td>0.002538</td>\n",
              "      <td>0.020302</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.010431</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.003073</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>0.001766</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.174173</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3126</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.001467</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>0.003264</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>1.484977</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.000957</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000520</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3127</td>\n",
              "      <td>0.001408</td>\n",
              "      <td>0.095829</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.001328</td>\n",
              "      <td>0.001195</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.123998</td>\n",
              "      <td>0.010130</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.108128</td>\n",
              "      <td>0.040098</td>\n",
              "      <td>0.002162</td>\n",
              "      <td>0.002441</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>0.364910</td>\n",
              "      <td>0.000955</td>\n",
              "      <td>0.019100</td>\n",
              "      <td>0.000447</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>0.000593</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>0.005068</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.238958</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.001039</td>\n",
              "      <td>0.003002</td>\n",
              "      <td>0.002261</td>\n",
              "      <td>0.004999</td>\n",
              "      <td>0.005648</td>\n",
              "      <td>0.011447</td>\n",
              "      <td>0.013820</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>0.005455</td>\n",
              "      <td>0.023943</td>\n",
              "      <td>0.028476</td>\n",
              "      <td>0.001866</td>\n",
              "      <td>0.004093</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.031014</td>\n",
              "      <td>0.113828</td>\n",
              "      <td>0.009285</td>\n",
              "      <td>0.102713</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.010439</td>\n",
              "      <td>0.037559</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.008292</td>\n",
              "      <td>0.000825</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.000481</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.003747</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.041257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3128</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000868</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000814</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.001295</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>0.000771</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>1.437782</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.009057</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>0.000863</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.004468</td>\n",
              "      <td>0.019428</td>\n",
              "      <td>0.005316</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000808</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.010189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3129</td>\n",
              "      <td>0.008889</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000709</td>\n",
              "      <td>0.000890</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.001493</td>\n",
              "      <td>0.000334</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000562</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.007144</td>\n",
              "      <td>0.001358</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>1.465005</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.002898</td>\n",
              "      <td>0.000487</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.000877</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.000295</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.002925</td>\n",
              "      <td>0.000068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id         0         1         2  ...        57        58        59        60\n",
              "0  3125  0.000044  0.003945  0.000032  ...  0.000301  0.174173  0.000010  0.000232\n",
              "1  3126  0.000469  0.000075  0.000007  ...  0.000428  0.000012  0.000011  0.000288\n",
              "2  3127  0.001408  0.095829  0.000110  ...  0.000164  0.003747  0.000249  0.041257\n",
              "3  3128  0.001122  0.000126  0.000222  ...  0.000808  0.000044  0.000027  0.010189\n",
              "4  3129  0.008889  0.000260  0.000030  ...  0.000161  0.000010  0.002925  0.000068\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb3lbN094bag"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}