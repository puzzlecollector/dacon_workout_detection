{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import re \n",
    "import keras\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, GRU, Conv2D, Conv2DTranspose, MaxPooling2D, AveragePooling2D, BatchNormalization, concatenate, ConvLSTM2D, Reshape, Conv3D, Flatten, LSTM, Dense, Dropout, Add\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalMaxPool1D, Attention\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "import random \n",
    "import time\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_features.csv') \n",
    "train_labels = pd.read_csv('train_labels.csv') \n",
    "test = pd.read_csv('test_features.csv') \n",
    "submission = pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 600, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.reshape(np.array(train.iloc[:,2:]), [-1,600,6]) \n",
    "X = np.asarray(X) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_labels['label'].values \n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():  \n",
    "    inputs = Input(shape = (600,18)) \n",
    "    bn = BatchNormalization()(inputs)\n",
    "    bi_gru = Bidirectional(GRU(128, return_sequences = True))(bn) \n",
    "    dropout = Dropout(0.25)(bi_gru) \n",
    "    bi_gru = Bidirectional(GRU(128, return_sequences = False))(dropout) \n",
    "    dense = Dense(128, activation = 'relu')(bi_gru) \n",
    "    bn = BatchNormalization()(dense) \n",
    "    outputs = Dense(61, activation = 'softmax')(bn)   \n",
    "    model = Model(inputs = inputs, outputs = outputs) \n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 285/2812 [00:00<00:00, 2846.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Validating on fold 1 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2812/2812 [00:01<00:00, 2753.25it/s]\n",
      "  3%|▎         | 897/30932 [00:00<00:03, 8964.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30932/30932 [00:03<00:00, 7823.85it/s]\n",
      "100%|██████████| 313/313 [00:00<00:00, 8529.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 99s 94ms/step - loss: 3.2264 - accuracy: 0.3370 - val_loss: 2.2503 - val_accuracy: 0.5144\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.25035, saving model to kfold1/epoch_001_val_2.250.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.9831 - accuracy: 0.5351 - val_loss: 1.5794 - val_accuracy: 0.5623\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.25035 to 1.57944, saving model to kfold1/epoch_002_val_1.579.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 1.2742 - accuracy: 0.6355 - val_loss: 1.1188 - val_accuracy: 0.6454\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.57944 to 1.11882, saving model to kfold1/epoch_003_val_1.119.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 1.0774 - accuracy: 0.6837 - val_loss: 1.0900 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.11882 to 1.09005, saving model to kfold1/epoch_004_val_1.090.h5\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.7882 - accuracy: 0.7588 - val_loss: 1.0064 - val_accuracy: 0.7061\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.09005 to 1.00640, saving model to kfold1/epoch_005_val_1.006.h5\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.6141 - accuracy: 0.8079 - val_loss: 0.9724 - val_accuracy: 0.7220\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00640 to 0.97240, saving model to kfold1/epoch_006_val_0.972.h5\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.4598 - accuracy: 0.8509 - val_loss: 1.1882 - val_accuracy: 0.6805\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97240\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.3611 - accuracy: 0.8857 - val_loss: 1.2017 - val_accuracy: 0.7157\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.97240\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 87s 89ms/step - loss: 0.2557 - accuracy: 0.9168 - val_loss: 1.1531 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97240\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.1894 - accuracy: 0.9400 - val_loss: 1.1179 - val_accuracy: 0.7476\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.97240\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.1240 - accuracy: 0.9618 - val_loss: 1.2203 - val_accuracy: 0.7252\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.97240\n",
      "Epoch 12/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.1044 - accuracy: 0.9676 - val_loss: 1.4869 - val_accuracy: 0.7125\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.97240\n",
      "Epoch 13/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.0816 - accuracy: 0.9766 - val_loss: 1.3447 - val_accuracy: 0.7348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2812 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_loss did not improve from 0.97240\n",
      "... Validating on fold 2 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2812/2812 [00:00<00:00, 2917.29it/s]\n",
      "  3%|▎         | 952/30932 [00:00<00:03, 9518.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30932/30932 [00:03<00:00, 8515.70it/s]\n",
      "100%|██████████| 313/313 [00:00<00:00, 8622.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 98s 93ms/step - loss: 3.2136 - accuracy: 0.3604 - val_loss: 2.3348 - val_accuracy: 0.4920\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.33475, saving model to kfold2/epoch_001_val_2.335.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.9135 - accuracy: 0.5437 - val_loss: 1.4610 - val_accuracy: 0.6198\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.33475 to 1.46101, saving model to kfold2/epoch_002_val_1.461.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.1968 - accuracy: 0.6565 - val_loss: 1.3173 - val_accuracy: 0.6358\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.46101 to 1.31727, saving model to kfold2/epoch_003_val_1.317.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.8600 - accuracy: 0.7411 - val_loss: 1.1966 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.31727 to 1.19661, saving model to kfold2/epoch_004_val_1.197.h5\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.6058 - accuracy: 0.8145 - val_loss: 1.2585 - val_accuracy: 0.6869\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.19661\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.4003 - accuracy: 0.8745 - val_loss: 1.2958 - val_accuracy: 0.6901\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.19661\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 90s 93ms/step - loss: 0.2412 - accuracy: 0.9270 - val_loss: 1.3844 - val_accuracy: 0.7093\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.19661\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.1788 - accuracy: 0.9461 - val_loss: 1.5823 - val_accuracy: 0.6869\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.19661\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.1120 - accuracy: 0.9674 - val_loss: 1.7735 - val_accuracy: 0.7157\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.19661\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 87s 89ms/step - loss: 0.0893 - accuracy: 0.9753 - val_loss: 1.7685 - val_accuracy: 0.6965\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.19661\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.0607 - accuracy: 0.9836 - val_loss: 1.7259 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 343/2812 [00:00<00:00, 3423.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss did not improve from 1.19661\n",
      "... Validating on fold 3 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2812/2812 [00:00<00:00, 3200.70it/s]\n",
      "  3%|▎         | 911/30932 [00:00<00:03, 9107.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30932/30932 [00:03<00:00, 8432.45it/s]\n",
      "100%|██████████| 313/313 [00:00<00:00, 9126.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 94s 92ms/step - loss: 3.1856 - accuracy: 0.3570 - val_loss: 2.1291 - val_accuracy: 0.5335\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.12909, saving model to kfold3/epoch_001_val_2.129.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.8170 - accuracy: 0.5533 - val_loss: 1.7428 - val_accuracy: 0.5655\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.12909 to 1.74283, saving model to kfold3/epoch_002_val_1.743.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 1.4867 - accuracy: 0.5963 - val_loss: 1.4040 - val_accuracy: 0.6262\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.74283 to 1.40396, saving model to kfold3/epoch_003_val_1.404.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 1.1676 - accuracy: 0.6597 - val_loss: 1.2431 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.40396 to 1.24308, saving model to kfold3/epoch_004_val_1.243.h5\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 1.0361 - accuracy: 0.6921 - val_loss: 1.1181 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.24308 to 1.11813, saving model to kfold3/epoch_005_val_1.118.h5\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.8540 - accuracy: 0.7399 - val_loss: 1.2057 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.11813\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.7223 - accuracy: 0.7828 - val_loss: 1.1817 - val_accuracy: 0.6965\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.11813\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.6295 - accuracy: 0.8067 - val_loss: 1.1928 - val_accuracy: 0.6933\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.11813\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.5156 - accuracy: 0.8410 - val_loss: 1.0748 - val_accuracy: 0.6901\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.11813 to 1.07482, saving model to kfold3/epoch_009_val_1.075.h5\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.4629 - accuracy: 0.8515 - val_loss: 1.1559 - val_accuracy: 0.7252\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.07482\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.3961 - accuracy: 0.8746 - val_loss: 1.3536 - val_accuracy: 0.6613\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.07482\n",
      "Epoch 12/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.3180 - accuracy: 0.8987 - val_loss: 1.1300 - val_accuracy: 0.7220\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.07482\n",
      "Epoch 13/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.2883 - accuracy: 0.9077 - val_loss: 1.2399 - val_accuracy: 0.6901\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.07482\n",
      "Epoch 14/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.3148 - accuracy: 0.8999 - val_loss: 1.1535 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.07482\n",
      "Epoch 15/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.2311 - accuracy: 0.9268 - val_loss: 1.2041 - val_accuracy: 0.7157\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.07482\n",
      "Epoch 16/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.1869 - accuracy: 0.9428 - val_loss: 1.2336 - val_accuracy: 0.7412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 373/2812 [00:00<00:00, 3727.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss did not improve from 1.07482\n",
      "... Validating on fold 4 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2812/2812 [00:00<00:00, 3230.56it/s]\n",
      "  3%|▎         | 971/30932 [00:00<00:03, 9704.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30932/30932 [00:03<00:00, 8287.68it/s]\n",
      "100%|██████████| 313/313 [00:00<00:00, 9785.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 93s 91ms/step - loss: 3.1840 - accuracy: 0.3590 - val_loss: 2.6167 - val_accuracy: 0.4984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.61665, saving model to kfold4/epoch_001_val_2.617.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.9789 - accuracy: 0.5368 - val_loss: 1.3806 - val_accuracy: 0.6198\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.61665 to 1.38064, saving model to kfold4/epoch_002_val_1.381.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 1.2924 - accuracy: 0.6336 - val_loss: 1.1459 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.38064 to 1.14592, saving model to kfold4/epoch_003_val_1.146.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.0212 - accuracy: 0.7053 - val_loss: 1.0527 - val_accuracy: 0.7029\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.14592 to 1.05272, saving model to kfold4/epoch_004_val_1.053.h5\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 88s 92ms/step - loss: 0.7644 - accuracy: 0.7693 - val_loss: 1.0924 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.05272\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.6136 - accuracy: 0.8088 - val_loss: 1.0424 - val_accuracy: 0.7188\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.05272 to 1.04244, saving model to kfold4/epoch_006_val_1.042.h5\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.4979 - accuracy: 0.8433 - val_loss: 0.9691 - val_accuracy: 0.7572\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.04244 to 0.96911, saving model to kfold4/epoch_007_val_0.969.h5\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.4054 - accuracy: 0.8744 - val_loss: 1.0964 - val_accuracy: 0.7188\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.96911\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.3128 - accuracy: 0.9000 - val_loss: 1.2425 - val_accuracy: 0.7188\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.96911\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.2294 - accuracy: 0.9269 - val_loss: 1.1897 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.96911\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.1914 - accuracy: 0.9381 - val_loss: 1.3220 - val_accuracy: 0.7220\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.96911\n",
      "Epoch 12/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.1456 - accuracy: 0.9536 - val_loss: 1.3360 - val_accuracy: 0.7188\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.96911\n",
      "Epoch 13/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.1247 - accuracy: 0.9621 - val_loss: 1.4196 - val_accuracy: 0.7284\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.96911\n",
      "Epoch 14/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.0958 - accuracy: 0.9713 - val_loss: 1.3237 - val_accuracy: 0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 392/2812 [00:00<00:00, 3909.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss did not improve from 0.96911\n",
      "... Validating on fold 5 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2812/2812 [00:00<00:00, 3415.55it/s]\n",
      "  3%|▎         | 966/30932 [00:00<00:03, 9657.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30932/30932 [00:03<00:00, 9094.86it/s]\n",
      "100%|██████████| 313/313 [00:00<00:00, 9519.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 92s 90ms/step - loss: 3.1997 - accuracy: 0.3527 - val_loss: 2.2515 - val_accuracy: 0.5240\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.25147, saving model to kfold5/epoch_001_val_2.251.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 1.8898 - accuracy: 0.5373 - val_loss: 1.4053 - val_accuracy: 0.6166\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.25147 to 1.40532, saving model to kfold5/epoch_002_val_1.405.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.2345 - accuracy: 0.6439 - val_loss: 1.2231 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.40532 to 1.22306, saving model to kfold5/epoch_003_val_1.223.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.9042 - accuracy: 0.7271 - val_loss: 1.2247 - val_accuracy: 0.6358\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.22306\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 87s 89ms/step - loss: 0.6853 - accuracy: 0.7886 - val_loss: 1.1379 - val_accuracy: 0.7220\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.22306 to 1.13793, saving model to kfold5/epoch_005_val_1.138.h5\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 90s 93ms/step - loss: 0.4803 - accuracy: 0.8510 - val_loss: 1.1873 - val_accuracy: 0.7093\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.13793\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.3889 - accuracy: 0.8779 - val_loss: 1.3041 - val_accuracy: 0.7093\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.13793\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.2524 - accuracy: 0.9218 - val_loss: 1.3441 - val_accuracy: 0.7220\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.13793\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.1994 - accuracy: 0.9384 - val_loss: 1.5615 - val_accuracy: 0.6773\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.13793\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.1292 - accuracy: 0.9608 - val_loss: 1.4835 - val_accuracy: 0.7316\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.13793\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.1101 - accuracy: 0.9663 - val_loss: 1.5818 - val_accuracy: 0.6933\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.13793\n",
      "Epoch 12/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.0855 - accuracy: 0.9740 - val_loss: 1.6523 - val_accuracy: 0.7061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 349/2813 [00:00<00:00, 3483.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss did not improve from 1.13793\n",
      "... Validating on fold 6 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [00:00<00:00, 3380.58it/s]\n",
      "  3%|▎         | 996/30943 [00:00<00:03, 9953.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30943/30943 [00:03<00:00, 9239.97it/s]\n",
      "100%|██████████| 312/312 [00:00<00:00, 9759.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 94s 92ms/step - loss: 3.1946 - accuracy: 0.3524 - val_loss: 2.3920 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.39202, saving model to kfold6/epoch_001_val_2.392.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 90s 93ms/step - loss: 1.8953 - accuracy: 0.5443 - val_loss: 1.3833 - val_accuracy: 0.5897\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.39202 to 1.38326, saving model to kfold6/epoch_002_val_1.383.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 1.2562 - accuracy: 0.6428 - val_loss: 1.1956 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.38326 to 1.19560, saving model to kfold6/epoch_003_val_1.196.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.9931 - accuracy: 0.7103 - val_loss: 1.1329 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.19560 to 1.13288, saving model to kfold6/epoch_004_val_1.133.h5\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.8807 - accuracy: 0.7365 - val_loss: 1.0667 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.13288 to 1.06674, saving model to kfold6/epoch_005_val_1.067.h5\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.7304 - accuracy: 0.7760 - val_loss: 1.0157 - val_accuracy: 0.7276\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.06674 to 1.01573, saving model to kfold6/epoch_006_val_1.016.h5\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.5898 - accuracy: 0.8192 - val_loss: 0.9357 - val_accuracy: 0.7436\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01573 to 0.93566, saving model to kfold6/epoch_007_val_0.936.h5\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.4646 - accuracy: 0.8540 - val_loss: 1.0657 - val_accuracy: 0.7308\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.93566\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.3831 - accuracy: 0.8764 - val_loss: 1.9742 - val_accuracy: 0.5224\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.93566\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.7689 - accuracy: 0.7612 - val_loss: 1.4018 - val_accuracy: 0.5994\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.93566\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.3913 - accuracy: 0.8727 - val_loss: 1.1360 - val_accuracy: 0.7179\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.93566\n",
      "Epoch 12/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.2836 - accuracy: 0.9082 - val_loss: 1.2104 - val_accuracy: 0.6987\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.93566\n",
      "Epoch 13/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.2395 - accuracy: 0.9228 - val_loss: 1.1431 - val_accuracy: 0.7372\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.93566\n",
      "Epoch 14/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.1855 - accuracy: 0.9387 - val_loss: 1.2409 - val_accuracy: 0.7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 372/2813 [00:00<00:00, 3718.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss did not improve from 0.93566\n",
      "... Validating on fold 7 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [00:00<00:00, 3366.90it/s]\n",
      "  3%|▎         | 991/30943 [00:00<00:03, 9901.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30943/30943 [00:03<00:00, 9279.92it/s]\n",
      "100%|██████████| 312/312 [00:00<00:00, 9103.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 100s 91ms/step - loss: 3.2141 - accuracy: 0.3441 - val_loss: 2.3279 - val_accuracy: 0.5160\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.32794, saving model to kfold7/epoch_001_val_2.328.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.8763 - accuracy: 0.5467 - val_loss: 1.5109 - val_accuracy: 0.5929\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.32794 to 1.51091, saving model to kfold7/epoch_002_val_1.511.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 1.3962 - accuracy: 0.6146 - val_loss: 1.2244 - val_accuracy: 0.6474\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.51091 to 1.22444, saving model to kfold7/epoch_003_val_1.224.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.0777 - accuracy: 0.6857 - val_loss: 1.2459 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.22444\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.8722 - accuracy: 0.7386 - val_loss: 1.0984 - val_accuracy: 0.6795\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.22444 to 1.09836, saving model to kfold7/epoch_005_val_1.098.h5\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.7106 - accuracy: 0.7837 - val_loss: 1.1536 - val_accuracy: 0.7083\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.09836\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.5832 - accuracy: 0.8169 - val_loss: 1.1828 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.09836\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.4278 - accuracy: 0.8664 - val_loss: 1.0667 - val_accuracy: 0.7244\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.09836 to 1.06667, saving model to kfold7/epoch_008_val_1.067.h5\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.3558 - accuracy: 0.8902 - val_loss: 1.2523 - val_accuracy: 0.7244\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.06667\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.2865 - accuracy: 0.9064 - val_loss: 1.1884 - val_accuracy: 0.6987\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.06667\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.2146 - accuracy: 0.9310 - val_loss: 1.2043 - val_accuracy: 0.7468\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.06667\n",
      "Epoch 12/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.1771 - accuracy: 0.9436 - val_loss: 1.3477 - val_accuracy: 0.7468\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.06667\n",
      "Epoch 13/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.1308 - accuracy: 0.9607 - val_loss: 1.3582 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.06667\n",
      "Epoch 14/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.1134 - accuracy: 0.9667 - val_loss: 1.3782 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.06667\n",
      "Epoch 15/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.0911 - accuracy: 0.9725 - val_loss: 1.4885 - val_accuracy: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 353/2813 [00:00<00:00, 3528.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss did not improve from 1.06667\n",
      "... Validating on fold 8 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [00:00<00:00, 3341.31it/s]\n",
      "  6%|▌         | 1810/30943 [00:00<00:03, 9268.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30943/30943 [00:03<00:00, 9129.52it/s]\n",
      "100%|██████████| 312/312 [00:00<00:00, 9629.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 94s 92ms/step - loss: 3.1879 - accuracy: 0.3584 - val_loss: 2.2572 - val_accuracy: 0.5224\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.25721, saving model to kfold8/epoch_001_val_2.257.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 1.9742 - accuracy: 0.5351 - val_loss: 1.3969 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.25721 to 1.39690, saving model to kfold8/epoch_002_val_1.397.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 1.3621 - accuracy: 0.6159 - val_loss: 1.1518 - val_accuracy: 0.6955\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.39690 to 1.15177, saving model to kfold8/epoch_003_val_1.152.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 1.1611 - accuracy: 0.6686 - val_loss: 1.1207 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.15177 to 1.12073, saving model to kfold8/epoch_004_val_1.121.h5\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.9531 - accuracy: 0.7190 - val_loss: 1.0218 - val_accuracy: 0.6923\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.12073 to 1.02178, saving model to kfold8/epoch_005_val_1.022.h5\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.7783 - accuracy: 0.7611 - val_loss: 1.1575 - val_accuracy: 0.6699\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.02178\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.8800 - accuracy: 0.7385 - val_loss: 1.0105 - val_accuracy: 0.7083\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.02178 to 1.01049, saving model to kfold8/epoch_007_val_1.010.h5\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.6208 - accuracy: 0.8069 - val_loss: 1.0513 - val_accuracy: 0.7115\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01049\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.5241 - accuracy: 0.8380 - val_loss: 1.1295 - val_accuracy: 0.7308\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.01049\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.4494 - accuracy: 0.8582 - val_loss: 1.1756 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.01049\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.4898 - accuracy: 0.8428 - val_loss: 1.1696 - val_accuracy: 0.7147\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.01049\n",
      "Epoch 12/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.3216 - accuracy: 0.8996 - val_loss: 1.2034 - val_accuracy: 0.7115\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.01049\n",
      "Epoch 13/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.2855 - accuracy: 0.9117 - val_loss: 1.1460 - val_accuracy: 0.7276\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.01049\n",
      "Epoch 14/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.3968 - accuracy: 0.8829 - val_loss: 1.2248 - val_accuracy: 0.7115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 374/2813 [00:00<00:00, 3739.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss did not improve from 1.01049\n",
      "... Validating on fold 9 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [00:00<00:00, 3422.48it/s]\n",
      "  3%|▎         | 973/30943 [00:00<00:03, 9728.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30943/30943 [00:03<00:00, 8949.13it/s]\n",
      "100%|██████████| 312/312 [00:00<00:00, 9053.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 96s 94ms/step - loss: 3.2317 - accuracy: 0.3419 - val_loss: 2.4597 - val_accuracy: 0.5192\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.45966, saving model to kfold9/epoch_001_val_2.460.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 1.9599 - accuracy: 0.5355 - val_loss: 1.4942 - val_accuracy: 0.6122\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.45966 to 1.49417, saving model to kfold9/epoch_002_val_1.494.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.4535 - accuracy: 0.6039 - val_loss: 1.6177 - val_accuracy: 0.5737\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.49417\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 1.1036 - accuracy: 0.6807 - val_loss: 1.8571 - val_accuracy: 0.5481\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.49417\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.0857 - accuracy: 0.6809 - val_loss: 1.1833 - val_accuracy: 0.7051\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.49417 to 1.18329, saving model to kfold9/epoch_005_val_1.183.h5\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.7668 - accuracy: 0.7697 - val_loss: 1.1474 - val_accuracy: 0.6955\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.18329 to 1.14743, saving model to kfold9/epoch_006_val_1.147.h5\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.6291 - accuracy: 0.8019 - val_loss: 1.1929 - val_accuracy: 0.7147\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.14743\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.5275 - accuracy: 0.8360 - val_loss: 1.1957 - val_accuracy: 0.7051\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.14743\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.3996 - accuracy: 0.8750 - val_loss: 1.1577 - val_accuracy: 0.7308\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.14743\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.3296 - accuracy: 0.8945 - val_loss: 1.1415 - val_accuracy: 0.7372\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.14743 to 1.14152, saving model to kfold9/epoch_010_val_1.142.h5\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.2879 - accuracy: 0.9066 - val_loss: 1.1615 - val_accuracy: 0.7276\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.14152\n",
      "Epoch 12/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.2283 - accuracy: 0.9270 - val_loss: 1.2325 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.14152\n",
      "Epoch 13/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.1777 - accuracy: 0.9433 - val_loss: 1.1625 - val_accuracy: 0.7564\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.14152\n",
      "Epoch 14/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.1518 - accuracy: 0.9530 - val_loss: 1.1893 - val_accuracy: 0.7564\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.14152\n",
      "Epoch 15/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.1095 - accuracy: 0.9682 - val_loss: 1.2620 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.14152\n",
      "Epoch 16/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.0958 - accuracy: 0.9732 - val_loss: 1.2352 - val_accuracy: 0.7756\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.14152\n",
      "Epoch 17/200\n",
      "967/967 [==============================] - 88s 91ms/step - loss: 0.0733 - accuracy: 0.9794 - val_loss: 1.2967 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 356/2813 [00:00<00:00, 3558.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: val_loss did not improve from 1.14152\n",
      "... Validating on fold 10 ...\n",
      "... Augmenting Data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2813/2813 [00:00<00:00, 3328.52it/s]\n",
      "  3%|▎         | 944/30943 [00:00<00:03, 9434.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Feature Engineering ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30943/30943 [00:03<00:00, 8820.62it/s]\n",
      "100%|██████████| 312/312 [00:00<00:00, 9378.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Training ...\n",
      "Epoch 1/200\n",
      "967/967 [==============================] - 93s 91ms/step - loss: 3.2065 - accuracy: 0.3529 - val_loss: 1.9622 - val_accuracy: 0.5481\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.96222, saving model to kfold10/epoch_001_val_1.962.h5\n",
      "Epoch 2/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 1.8425 - accuracy: 0.5442 - val_loss: 1.2746 - val_accuracy: 0.6506\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.96222 to 1.27460, saving model to kfold10/epoch_002_val_1.275.h5\n",
      "Epoch 3/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 1.2181 - accuracy: 0.6476 - val_loss: 1.1693 - val_accuracy: 0.6859\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.27460 to 1.16934, saving model to kfold10/epoch_003_val_1.169.h5\n",
      "Epoch 4/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.8909 - accuracy: 0.7315 - val_loss: 1.0859 - val_accuracy: 0.7083\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.16934 to 1.08586, saving model to kfold10/epoch_004_val_1.086.h5\n",
      "Epoch 5/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.6996 - accuracy: 0.7810 - val_loss: 1.1644 - val_accuracy: 0.7051\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.08586\n",
      "Epoch 6/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.5208 - accuracy: 0.8334 - val_loss: 1.1476 - val_accuracy: 0.7083\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.08586\n",
      "Epoch 7/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.3354 - accuracy: 0.8935 - val_loss: 1.1094 - val_accuracy: 0.7532\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.08586\n",
      "Epoch 8/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.2331 - accuracy: 0.9264 - val_loss: 1.1879 - val_accuracy: 0.7372\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.08586\n",
      "Epoch 9/200\n",
      "967/967 [==============================] - 87s 90ms/step - loss: 0.1580 - accuracy: 0.9512 - val_loss: 1.3153 - val_accuracy: 0.7468\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.08586\n",
      "Epoch 10/200\n",
      "967/967 [==============================] - 89s 92ms/step - loss: 0.1236 - accuracy: 0.9618 - val_loss: 1.3176 - val_accuracy: 0.7308\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.08586\n",
      "Epoch 11/200\n",
      "967/967 [==============================] - 86s 89ms/step - loss: 0.0978 - accuracy: 0.9689 - val_loss: 1.3724 - val_accuracy: 0.7372\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.08586\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits = 10, random_state = 960418, shuffle = True)\n",
    "for idx,(train_idx, val_idx) in enumerate(kfold.split(X,y)):   \n",
    "    print(\"... Validating on fold {} ...\".format(idx+1)) \n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx] \n",
    "    \n",
    "    ##### augment data #####\n",
    "    print(\"... Augmenting Data ...\")\n",
    "    X_augmented = [] \n",
    "    y_augmented = [] \n",
    "    for i in tqdm(range(X_train.shape[0])): \n",
    "        for j in range(10): \n",
    "            shifted = np.roll(X_train[i], int(random.random() * 600)) \n",
    "            X_augmented.append(shifted) \n",
    "            y_augmented.append(y_train[i]) \n",
    "    X_augmented = np.asarray(X_augmented) \n",
    "    y_augmented = np.asarray(y_augmented)\n",
    "    X_train = np.concatenate([X_train, X_augmented]) \n",
    "    y_train = np.concatenate([y_train, y_augmented])\n",
    "    \n",
    "    ###### feature engineering data ##### \n",
    "    print(\"... Feature Engineering ...\")\n",
    "    X_fourier_real = [] \n",
    "    X_fourier_imag = [] \n",
    "    for i in tqdm(range(X_train.shape[0]), position = 0, leave = True):  \n",
    "        real_part = np.fft.fft(X_train[i]).real \n",
    "        imag_part = np.fft.fft(X_train[i]).imag \n",
    "        X_fourier_real.append(real_part)\n",
    "        X_fourier_imag.append(imag_part) \n",
    "    \n",
    "    X_fourier_real = np.asarray(X_fourier_real)  \n",
    "    X_fourier_imag = np.asarray(X_fourier_imag)\n",
    "    X_train = np.concatenate([X_train, X_fourier_real, X_fourier_imag], axis = 2)   \n",
    "    \n",
    "    \n",
    "    X_val_fourier_real = [] \n",
    "    X_val_fourier_imag = [] \n",
    "    for i in tqdm(range(X_val.shape[0]), position = 0, leave = True):\n",
    "        real_part = np.fft.fft(X_val[i]).real \n",
    "        imag_part = np.fft.fft(X_val[i]).imag \n",
    "        X_val_fourier_real.append(real_part) \n",
    "        X_val_fourier_imag.append(imag_part)\n",
    "    \n",
    "    X_val_fourier_real = np.asarray(X_val_fourier_real) \n",
    "    X_val_fourier_imag = np.asarray(X_val_fourier_imag)\n",
    "    X_val = np.concatenate([X_val, X_val_fourier_real, X_val_fourier_imag], axis = 2)\n",
    "        \n",
    "    \n",
    "    ##### train model #####  \n",
    "    print(\"... Training ...\") \n",
    "    model = build_model() \n",
    "    model_path = 'kfold' + str(idx+1) + '/epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 2, verbose = 1, factor = 0.8)\n",
    "    checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 7) \n",
    "\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              epochs = 200,\n",
    "              batch_size = 32,\n",
    "              validation_data = (X_val, y_val),\n",
    "              callbacks = [learning_rate_reduction, checkpoint, early_stopping])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru1 = load_model('kfold1/epoch_006_val_0.972.h5')\n",
    "gru2 = load_model('kfold2/epoch_004_val_1.197.h5') \n",
    "gru3 = load_model('kfold3/epoch_009_val_1.075.h5')  \n",
    "gru4 = load_model('kfold4/epoch_007_val_0.969.h5') \n",
    "gru5 = load_model('kfold5/epoch_005_val_1.138.h5')\n",
    "gru6 = load_model('kfold6/epoch_007_val_0.936.h5')\n",
    "gru7 = load_model('kfold7/epoch_008_val_1.067.h5')\n",
    "gru8 = load_model('kfold8/epoch_007_val_1.010.h5')\n",
    "gru9 = load_model('kfold9/epoch_010_val_1.142.h5') \n",
    "gru10 = load_model('kfold10/epoch_004_val_1.086.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:00<00:00, 9035.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(782, 600, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = tf.reshape(np.array(test.iloc[:,2:]),[-1, 600, 6])\n",
    "X_test = np.asarray(test_X)\n",
    "\n",
    "##### feature engineering for test dataset ##### \n",
    "X_test_fourier_real = [] \n",
    "X_test_fourier_imag = [] \n",
    "for i in tqdm(range(X_test.shape[0]), position = 0, leave = True):\n",
    "    real_part = np.fft.fft(X_test[i]).real \n",
    "    imag_part = np.fft.fft(X_test[i]).imag \n",
    "    X_test_fourier_real.append(real_part) \n",
    "    X_test_fourier_imag.append(imag_part)\n",
    "    \n",
    "X_test_fourier_real = np.asarray(X_test_fourier_real) \n",
    "X_test_fourier_imag = np.asarray(X_test_fourier_imag)\n",
    "X_test = np.concatenate([X_test, X_test_fourier_real, X_test_fourier_imag], axis = 2)  \n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = gru1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = gru2.predict(X_test)\n",
    "p3 = gru3.predict(X_test)\n",
    "p4 = gru4.predict(X_test) \n",
    "p5 = gru5.predict(X_test) \n",
    "p6 = gru6.predict(X_test)\n",
    "p7 = gru7.predict(X_test) \n",
    "p8 = gru8.predict(X_test) \n",
    "p9 = gru9.predict(X_test) \n",
    "p10 = gru10.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_avg = (p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9 + p10)/10.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:,1:] = p_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>1.592733e-05</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>4.770708e-08</td>\n",
       "      <td>0.352726</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011902</td>\n",
       "      <td>5.910614e-04</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>1.436803e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.122010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>5.921524e-06</td>\n",
       "      <td>0.021470</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>6.673528e-05</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6.659289e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>3.787994e-05</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>6.210780e-06</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>1.618933e-04</td>\n",
       "      <td>0.070613</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>3.588521e-03</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>8.133279e-06</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.015425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.616908e-05</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.350694e-06</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>3.847815e-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5.054480e-05</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>0.049436</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>1.857505e-07</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.031574</td>\n",
       "      <td>1.093202e-05</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.700347e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.227133e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id         0         1             2         3         4             5  \\\n",
       "0  3125  0.000035  0.008070  1.592733e-05  0.000018  0.000013  4.770708e-08   \n",
       "1  3126  0.000126  0.000812  5.921524e-06  0.021470  0.000004  6.673528e-05   \n",
       "2  3127  0.000486  0.003486  6.210780e-06  0.000033  0.001839  1.618933e-04   \n",
       "3  3128  0.000218  0.000011  4.616908e-05  0.000032  0.000003  3.350694e-06   \n",
       "4  3129  0.049436  0.004557  1.857505e-07  0.000031  0.031574  1.093202e-05   \n",
       "\n",
       "          6         7         8  ...        51            52        53  \\\n",
       "0  0.352726  0.002920  0.000025  ...  0.011902  5.910614e-04  0.000436   \n",
       "1  0.000018  0.002538  0.000017  ...  0.000009  6.659289e-07  0.000004   \n",
       "2  0.070613  0.000983  0.000256  ...  0.000582  3.588521e-03  0.000041   \n",
       "3  0.000014  0.000017  0.000010  ...  0.000118  3.847815e-05  0.000034   \n",
       "4  0.000067  0.000006  0.000038  ...  0.000013  1.700347e-06  0.000002   \n",
       "\n",
       "         54            55        56        57        58        59        60  \n",
       "0  0.001321  1.436803e-06  0.000013  0.000198  0.122010  0.000005  0.000023  \n",
       "1  0.000250  3.787994e-05  0.000515  0.000336  0.000006  0.000032  0.000115  \n",
       "2  0.001242  8.133279e-06  0.000025  0.000115  0.019070  0.000449  0.015425  \n",
       "3  0.000061  5.054480e-05  0.000014  0.000958  0.000188  0.000006  0.003009  \n",
       "4  0.000001  5.227133e-07  0.000014  0.000324  0.000097  0.000037  0.000634  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"fourier_transform_10_fold_gru.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
